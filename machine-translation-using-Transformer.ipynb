{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Steps and Challenges & Possible solution: \n",
    "1. Text Preprocessing and Tokenization: Using the pretrained BERT Model ( multilingual cased)\n",
    "2. Model Training and Fine-tuning\n",
    "3. Fine-tune the inferencing time\n",
    "\n",
    "Link: https://arxiv.org/pdf/2309.13222 \n",
    "\n",
    "Transformer Paper Link: https://towardsdatascience.com/build-your-own-transformer-from-scratch-using-pytorch-84c850470dcb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/faiyazahmad/anaconda3/envs/deep_learning/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "## import important libraries\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import math\n",
    "from transformers import AutoTokenizer  ## Hugging Face \n",
    "import tqdm as notebook_tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('weights/tmodel_00.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def causal_mask(size):\n",
    "    mask = torch.triu(torch.ones(1,size,size), diagonal=1).type(torch.int)\n",
    "    return mask == 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ True, False, False, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False, False, False, False, False, False],\n",
       "         [ True,  True, False, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False, False, False, False, False, False],\n",
       "         [ True,  True,  True, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False, False, False, False, False, False],\n",
       "         [ True,  True,  True,  True, False, False, False, False, False, False,\n",
       "          False, False, False, False, False, False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True, False, False, False, False, False,\n",
       "          False, False, False, False, False, False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True, False, False, False, False,\n",
       "          False, False, False, False, False, False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
       "          False, False, False, False, False, False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "          False, False, False, False, False, False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "          False, False, False, False, False, False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          False, False, False, False, False, False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True, False, False, False, False, False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True, False, False, False, False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True, False, False, False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True, False, False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True, False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "causal_mask(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encoder_input = torch.tensor([\n",
    "    [[i for i in range(0,8)],[i for i in range(0,8)]],\n",
    "    [[i for i in range(0,8)],[i for i in range(0,8)]],\n",
    "     [[i for i in range(0,8)],[i for i in range(0,8)]]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder=torch.randint(0, 20, (5, 10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=open(\"data/train.en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mType:\u001b[0m        BufferedReader\n",
       "\u001b[0;31mString form:\u001b[0m <_io.BufferedReader name='data/train.en'>\n",
       "\u001b[0;31mDocstring:\u001b[0m   Create a new buffered reader using the given readable raw IO object."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file.buffer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 5])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS is available\n"
     ]
    }
   ],
   "source": [
    "# Check that MPS is available\n",
    "if not torch.backends.mps.is_available():\n",
    "    if not torch.backends.mps.is_built():\n",
    "        print(\"MPS not available because the current PyTorch install was not \"\n",
    "              \"built with MPS enabled.\")\n",
    "    else:\n",
    "        print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "              \"and/or you do not have an MPS-enabled device on this machine.\")\n",
    "\n",
    "else:\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    print(\"MPS is available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer  ## Hugging Face \n",
    "tokenizer=AutoTokenizer.from_pretrained(\"google-bert/bert-base-multilingual-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] चोरी नहीं हत्या करना था मकसद, नफरत से भरे थे हत्यारे ; हिरासत में चार संदिग्ध [SEP]'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(\"चोरी नहीं हत्या करना था मकसद, नफरत से भरे थे हत्‍यारे; हिरासत में चार संदिग्ध\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention,self).__init__()\n",
    "        assert d_model % num_heads ==0 , \"d_model must be divisible by num_heads\"\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads\n",
    "        self.W_q = nn.Linear(d_model, d_model)\n",
    "        self.W_k = nn.Linear(d_model, d_model)\n",
    "        self.W_v = nn.Linear(d_model, d_model)\n",
    "        self.W_o = nn.Linear(d_model, d_model)\n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
    "        attn_scores = torch.matmul(Q, K.transpose(-2,-1)) / math.sqrt(self.d_k)\n",
    "        if mask is not None: \n",
    "            attn_scores = attn_scores.masked_fill(mask == 0 , -1e9)\n",
    "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
    "        output = torch.matmul(attn_probs, V)\n",
    "        return output\n",
    "    def split_heads(self,x):\n",
    "        batch_size, _, seq_length, d_k = x.size()\n",
    "        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1,2)\n",
    "    def combine_heads(self,x):\n",
    "        batch_size, _, seq_length, d_k = x.size()\n",
    "        return x.transpose(1,2).contiguous().view(batch_size, seq_length, self.d_model)\n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        Q = self.split_heads(self.W_q(Q))\n",
    "        K = self.split_heads(self.W_k(K))\n",
    "        V = self.split_heads(self.W_v(V))\n",
    "        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n",
    "        output = self.W_o(self.combine_heads(attn_output))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=MultiHeadAttention(64,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len=512\n",
    "d_model=64\n",
    "pe = torch.zeros(seq_len, d_model)\n",
    "\n",
    "        # creata a vector of shape (seq_len)\n",
    "position = torch.arange(0, seq_len, dtype=torch.float).unsqueeze(1)\n",
    "div_term = torch.exp(torch.arange(0,d_model,2).float()*(-math.log(10000.0)/d_model))\n",
    "        # Apply the sin to even position \n",
    "pe[:, 0::2] = torch.sin(position*div_term)\n",
    "pe[:,1::2] = torch.cos(position*div_term)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 1])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(0, seq_len, dtype=torch.float).unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(0, seq_len, dtype=torch.float).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 64])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pe.unsqueeze(0)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "However, Paes, who was partnering Australia's Paul Hanley, could only go as far as the quarterfinals where they lost to Bhupathi and Knowles\n",
      "\n",
      "Whosoever desires the reward of the world, with Allah is the reward of the world and of the Everlasting Life. Allah is the Hearer, the Seer.\n",
      "\n",
      "The value of insects in the biosphere is enormous because they outnumber all other living groups in measure of species richness.\n",
      "\n",
      "Mithali To Anchor Indian Team Against Australia in ODIs\n",
      "\n",
      "After the assent of the Honble President on 8thSeptember, 2016, the 101thConstitutional Amendment Act, 2016 came into existence\n",
      "\n",
      "The court has fixed a hearing for February 12\n",
      "\n",
      "Please select the position where the track should be split.\n",
      "\n",
      "As per police, armys 22RR, special operation Group (SOG) of police and the Central Reserve Police Force (CRPF) cordoned the village and launched search operation in the area.\n",
      "\n",
      "Jharkhand chief minister Hemant Soren\n",
      "\n",
      "Arvind Kumar, SHO of the sector 55/56 police station, said a case has been registered under section 376-D (gang rape) of the Indian Penal Code.\n",
      "\n",
      "Briefing media in New Delhi today, party's State-in-charge, Anil Jain said, after the meeting the party will meet the Governor to stake claim for government formation in the state.\n",
      "\n",
      "\"Jesus responded, as he taught in the temple, \"\"How is it that the scribes say that the Christ is the son of David?\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f=open(\"data/train.en\",'r')\n",
    "count=0\n",
    "for i in f.readlines():\n",
    "    print(i)\n",
    "    if count>10:\n",
    "        break\n",
    "    count=count+1\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "आस्ट्रेलिया के पाल हेनली के साथ जोड़ी बनाने वाले पेस मियामी में क्वार्टरफाइनल तक ही पहुंच सके क्योंकि इस दौर में उन्हें भूपति और नोल्स ने हराया था।\n",
      "\n",
      "और जो शख्स (अपने आमाल का) बदला दुनिया ही में चाहता है तो ख़ुदा के पास दुनिया व आख़िरत दोनों का अज्र मौजूद है और ख़ुदा तो हर शख्स की सुनता और सबको देखता है\n",
      "\n",
      "जैव-मंडल में कीड़ों का मूल्य बहुत है, क्योंकि प्रजातियों की समृद्धि के मामले में उनकी संख्या अन्य जीव समूहों से ज़्यादा है।\n",
      "\n",
      "आस्ट्रेलिया के खिलाफ वनडे टीम की कमान मिताली को\n",
      "\n",
      "8 सितम्‍बर, 2016 को माननीय राष्‍ट्रपति की स्‍वीकृति मिलने के बाद 101वां संविधान संशोधन अधिनियम, 2016 अस्तित्‍व में आया\n",
      "\n",
      "अदालत ने इस मामले में आगे की सुनवाई के लिए एक फरवरी की तारीख़ तय की\n",
      "\n",
      "जहाँ पर ट्रैक को विभाजित किया जाना है, कृपया वह स्थान चुनें.\n",
      "\n",
      "इसके तुरंत बाद सेना की 22 राष्ट्रीय राइफल्स (आरआर), सीआरपीएफ और पुलिस के स्पेशल ऑपरेशन ग्रुप (एसओजी) के जवानों द्वारा इलाके की घेराबंदी कर तलाशी अभियान चलाया।\n",
      "\n",
      "झारखंड के मुख्यमंत्री हेमंत सोरेन (फोटोः पीटीआई)\n",
      "\n",
      "सेक्टर 55/56 के एसएचओ अरविंद कुमार ने बताया कि इस मामले में आईपीसी की धारा 376-डी (गैंगरेप) के तहत मामला दर्ज कर लिया गया है।\n",
      "\n",
      "आज नई दिल्ली में मीडिया से बातचीत में पार्टी के राज्य प्रभारी अनिल जैन ने बताया कि बैठक के बाद पार्टी, सरकार के गठन का दावा पेश करने के लिए राज्यपाल से मिलेगी।\n",
      "\n",
      "फिर यीशु ने मन्दिर में उपदेश करते हुए यह कहा, कि शास्त्री क्योंकर कहते हैं, कि मसीह दाऊद का पुत्रा है?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f=open(\"data/train.hi\",'r')\n",
    "count=0\n",
    "for i in f.readlines():\n",
    "    print(i)\n",
    "    if count>10:\n",
    "        break\n",
    "    count=count+1\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text=\"As per police, armys 22RR, special operation Group (SOG) of police and the Central Reserve Police Force (CRPF) cordoned the village and launched search operation in the area.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_preprocessing():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def preprocess(self,text):\n",
    "        # Replace non-breaking space with space\n",
    "        text = text.replace('\\u202f', ' ').replace('\\xa0', ' ')\n",
    "        # Insert space between words and punctuation marks\n",
    "        no_space = lambda char, prev_char: char in ',.!?।' and prev_char != ' '\n",
    "        out = [' ' + char if i > 0 and no_space(char, text[i - 1]) else char for i, char in enumerate(text.lower())]\n",
    "        return ''.join(out)\n",
    "    def tokenize(self,text):\n",
    "        sequence=['<SOS>']\n",
    "        sequence.extend(text.split())\n",
    "        sequence.append('<EOS>')\n",
    "        return sequence\n",
    "    def seq_to_idx(self,sequence,vocab):\n",
    "        indexed_sequence=[]\n",
    "        for i in sequence:\n",
    "            if i in vocab:\n",
    "                indexed_sequence.append(vocab[i])\n",
    "            else:\n",
    "                indexed_sequence.append(vocab['<UNK>'])\n",
    "        return indexed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 75, 1, 77, 74, 78, 79, 50, 80, 81, 5, 82, 83, 84, 85, 1, 77, 87, 14, 88, 3]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=\"8 सितम्‍बर, 2016 को माननीय राष्‍ट्रपति की स्‍वीकृति मिलने के बाद 101वां संविधान संशोधन अधिनियम, 2016 अस्तित्‍व में आया\"\n",
    "dat=data_preprocessing()\n",
    "#cln=dat.preprocess(a)\n",
    "seq=dat.tokenize(a)\n",
    "idx_seq=dat.seq_to_idx(seq,hin_vocab)\n",
    "idx_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Vocab\n",
    "eng_vocab={'<PAD>':0,'<UNK>':1,'<SOS>':2,'<EOS>':3}\n",
    "eng_vocab_transform={}\n",
    "hin_vocab={'<PAD>':0,'<UNK>':1,'<SOS>':2,'<EOS>':3}\n",
    "hin_vocab_transform={}   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hindi ( First 1000 sentence)\n",
    "f=open(\"data/train.hi\",'r')\n",
    "hin_vocab={'<PAD>':0,'<UNK>':1,'<SOS>':2,'<EOS>':3}\n",
    "count=0\n",
    "hindi=[]\n",
    "count=0\n",
    "data_prep=data_preprocessing()\n",
    "for text in f.readlines():\n",
    "    text=data_prep.preprocess(text)\n",
    "    tokens=data_prep.tokenize(text)\n",
    "    for token in tokens:\n",
    "        if token in hin_vocab:\n",
    "            continue\n",
    "        else:\n",
    "            hin_vocab[token]=len(hin_vocab)  \n",
    "    if count>1000:\n",
    "        break\n",
    "    count=count+1\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hindi ( First 1000 sentence)\n",
    "f=open(\"data/train.en\",'r')\n",
    "count=0\n",
    "data_prep=data_preprocessing()\n",
    "for text in f.readlines():\n",
    "    text=data_prep.preprocess(text)\n",
    "    tokens=data_prep.tokenize(text)\n",
    "    for token in tokens:\n",
    "        if token in eng_vocab:\n",
    "            continue\n",
    "        else:\n",
    "            eng_vocab[token]=len(eng_vocab)  \n",
    "    if count>1000:\n",
    "        break\n",
    "    count=count+1\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=PositionalEncoding(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "position = torch.arange(100).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.09019210189580917,\n",
       "  'token': 4633,\n",
       "  'token_str': 'fashion',\n",
       "  'sequence': \"Hello I'm a fashion model.\"},\n",
       " {'score': 0.06350002437829971,\n",
       "  'token': 1207,\n",
       "  'token_str': 'new',\n",
       "  'sequence': \"Hello I'm a new model.\"},\n",
       " {'score': 0.06228209286928177,\n",
       "  'token': 2581,\n",
       "  'token_str': 'male',\n",
       "  'sequence': \"Hello I'm a male model.\"},\n",
       " {'score': 0.04417283087968826,\n",
       "  'token': 1848,\n",
       "  'token_str': 'professional',\n",
       "  'sequence': \"Hello I'm a professional model.\"},\n",
       " {'score': 0.03326152637600899,\n",
       "  'token': 7688,\n",
       "  'token_str': 'super',\n",
       "  'sequence': \"Hello I'm a super model.\"}]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker = pipeline('fill-mask', model='bert-base-cased')\n",
    "unmasker(\"Hello I'm a [MASK] model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unmasker(\"Hello I'm a [MASK] model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe = torch.zeros(64,1,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_size = 64\n",
    "max_len = 100\n",
    "div_term = torch.exp(torch.arange(0,emb_size,2) * (-math.log(10000.0)/emb_size))\n",
    "div_term.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "position = torch.arange(max_len).reshape(max_len,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000e+00, 7.4989e-01, 5.6234e-01, 4.2170e-01, 3.1623e-01, 2.3714e-01,\n",
       "        1.7783e-01, 1.3335e-01, 1.0000e-01, 7.4989e-02, 5.6234e-02, 4.2170e-02,\n",
       "        3.1623e-02, 2.3714e-02, 1.7783e-02, 1.3335e-02, 1.0000e-02, 7.4989e-03,\n",
       "        5.6234e-03, 4.2170e-03, 3.1623e-03, 2.3714e-03, 1.7783e-03, 1.3335e-03,\n",
       "        1.0000e-03, 7.4989e-04, 5.6234e-04, 4.2170e-04, 3.1623e-04, 2.3714e-04,\n",
       "        1.7783e-04, 1.3335e-04])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "div_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 32])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=position*div_term\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, emb_size: int, dropout: float = 0.1, max_len : int = 100):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        position = torch.arange(max_len).reshape(max_len,1)\n",
    "        div_term = torch.exp(torch.arange(0,emb_size,2) * (-math.log(10000.0)/emb_size))\n",
    "        pe = torch.zeros(max_len, 1, emb_size)\n",
    "        pe[:, 0, 0::2] = torch.sin(position* div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position* div_term)\n",
    "        self.register_buffer('pe',pe)\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "           x: Tensor, shape ``[seq_len, batch_size ,embedding_dim]``\n",
    "        \"\"\"\n",
    "        x = x+self.pe[:x.size(0)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size,emb_size)\n",
    "        self.emb_size = emb_size\n",
    "    def forward(self,tokens: Tensor):\n",
    "        return self.embedding(tokens.long())*math.sqrt(self.emb_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size=100\n",
    "emb_size=64\n",
    "e=nn.Embedding(vocab_size,emb_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.2787, -0.5009, -0.6734,  ..., -0.3532,  0.2240,  0.9667],\n",
       "        [ 2.4530,  1.0345, -1.7734,  ...,  1.3107, -0.1280, -1.8023],\n",
       "        [ 1.3118, -2.0575,  0.8235,  ..., -1.1269,  0.2530, -0.7042],\n",
       "        ...,\n",
       "        [ 0.1233, -0.3748, -1.9727,  ..., -1.1965, -1.1139, -1.9265],\n",
       "        [ 0.4807, -0.3565, -0.9671,  ..., -0.0933, -0.9233, -0.7316],\n",
       "        [-0.7822, -1.1744, -0.4744,  ...,  2.6805,  0.7909, -0.1247]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58.37255859375"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size*128*4/(1024*1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence to Sequence Network\n",
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(self, \n",
    "                 num_encoder_layers: int,\n",
    "                 num_decoder_layers: int,\n",
    "                 emb_size: int, \n",
    "                 nhead: int, \n",
    "                 src_vocab_size: int,\n",
    "                 tgt_vocab_size: int,\n",
    "                 dim_feedforward: int = 512,\n",
    "                 dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.transformer = Transformer(d_model = emb_size,\n",
    "                                       nhead = nhead,\n",
    "                                       num_encoder_layers = num_encoder_layers,\n",
    "                                       num_decoder_layers = num_decoder_layers,\n",
    "                                       dim_feedforward = dim_feedforward,\n",
    "                                       dropout=dropout)\n",
    "        self.generator = nn.Linear(emb_size,tgt_vocab_size)\n",
    "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
    "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
    "        self.positional_encoding = PositionalEncoding(emb_size,dropout=dropout)\n",
    "\n",
    "    def forward(self, \n",
    "                src: Tensor,\n",
    "                tgt: Tensor, \n",
    "                src_mask: Tensor,\n",
    "                tgt_mask: Tensor,\n",
    "                src_padding_mask: Tensor,\n",
    "                tgt_padding_mask: Tensor,\n",
    "                memory_key_padding_mask: Tensor):\n",
    "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
    "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
    "        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None, src_padding_mask, tgt_padding_mask,\n",
    "                                memory_key_padding_mask)\n",
    "        return self.generator(outs)\n",
    "\n",
    "    def encode(self, src: Tensor, src_mask: Tensor):\n",
    "        x = self.positional_encoding(self.src_tok_emb(src))\n",
    "        return self.transformer.encoder(x, src_mask)\n",
    "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
    "        x = self.positional_encoding(self.tgt_tok_emb(tgt))\n",
    "        return self.transformer.decoder(x, memory, tgt_mask)\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_encoder_layers=10\n",
    "num_decoder_layers=20\n",
    "emb_size=64\n",
    "nhead=8\n",
    "src_vocab_size=10000\n",
    "tgt_vocab_size=10000\n",
    "dim_feedforward=128\n",
    "dropout=0.2\n",
    "mod=Seq2SeqTransformer(num_encoder_layers,\n",
    "                 num_decoder_layers,\n",
    "                 emb_size, \n",
    "                 nhead, \n",
    "                 src_vocab_size,\n",
    "                 tgt_vocab_size,\n",
    "                 dim_feedforward,\n",
    "                 dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2SeqTransformer(\n",
       "  (transformer): Transformer(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-9): 10 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
       "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.2, inplace=False)\n",
       "          (dropout2): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-19): 20 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
       "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.2, inplace=False)\n",
       "          (dropout2): Dropout(p=0.2, inplace=False)\n",
       "          (dropout3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (generator): Linear(in_features=64, out_features=10000, bias=True)\n",
       "  (src_tok_emb): TokenEmbedding(\n",
       "    (embedding): Embedding(10000, 64)\n",
       "  )\n",
       "  (tgt_tok_emb): TokenEmbedding(\n",
       "    (embedding): Embedding(10000, 64)\n",
       "  )\n",
       "  (positional_encoding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones((sz,sz), device = DEVICE) == 1)).transpose(0,1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "def create_mask(src, tgt):\n",
    "    src_seq_len = src.shape[0]\n",
    "    tgt_seq_len = tgt.shape[0]\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len), device=DEVICE).type(torch.bool)\n",
    "    src_padding_mask = (src == PAD_IDX).transpose(0,1)\n",
    "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0,1)\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "src_vocab_size = 100\n",
    "tgt_vocab_size = 200\n",
    "emb_size = 64\n",
    "nhead = 4\n",
    "ffn_hid_dim = 128\n",
    "batch_size = 32\n",
    "num_encoder_layers = 2\n",
    "num_decoder_layers = 3\n",
    "transformer = Seq2SeqTransformer(num_encoder_layers, num_decoder_layers, emb_size, nhead, src_vocab_size, tgt_vocab_size, ffn_hid_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in transformer.parameters():\n",
    "    if p.dim()>1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "transformer = transformer.to(DEVICE)\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.001, betas=(0.9,0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to club together sequential operations\n",
    "def sequential_transform(*transforms):\n",
    "    def func(txt_input):\n",
    "        for transform in transforms: \n",
    "            txt_input = transform(txt_input)\n",
    "        return txt_input\n",
    "    return func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add BOS/EOS and create tensor for input sequence indices\n",
    "def tensor_transform(token_ids: List[int]):\n",
    "    x1 = torch.tensor([BOS_IDX])\n",
    "    x2 = torch.tensor(token_ids)\n",
    "    x3 = torch.tensor([EOS_IDX])\n",
    "    x = torch.cat((x1,x2,x3))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ``src`` and ``tgt`` language text transforms to convert raw strings into tensors indices \n",
    "text_transform = {}\n",
    "for ln in [src_lang, tgt_lang]:\n",
    "    text_transform[ln] = sequential_transforms(token_transform[ln], # Tokenization\n",
    "                                               vocab_transform[ln], # Numericalization\n",
    "                                               tensor_transform) # Add BOS/EOS and create tensor \n",
    "\n",
    "# Function to collate data samples into batch tensors\n",
    "def collate_fn(batch):\n",
    "    src_batch, tgt_batch = [], []\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8406"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids(\"fake\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=AutoTokenizer.from_pretrained(\"google-bert/bert-base-multilingual-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt=\"टी20 वर्ल्ड कप जीतकर लौटने वाली टीम इंडिया का मुंबई में काफी शानदार स्वागत किया गया। इस दौरान मुंबई की सड़कों पर जमकर भीड़ देखने को मिली। फैंस टीम इंडिया के सितारों की एक झलक पाने के लिए उतावले थे। इस दौरान फैंस ने कुछ ऐसा कर दिया जिससे उन्हें खुद काफी नुकसान हो सकता था। फैंस ने सितारों की झलक पाने के लिए अपनी जान जोखिम में डाली\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tokenizer.encode(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101,\n",
       " 100,\n",
       " 100,\n",
       " 607,\n",
       " 28519,\n",
       " 610,\n",
       " 28533,\n",
       " 28515,\n",
       " 28510,\n",
       " 28524,\n",
       " 100,\n",
       " 623,\n",
       " 28531,\n",
       " 28525,\n",
       " 28533,\n",
       " 100,\n",
       " 100,\n",
       " 607,\n",
       " 28531,\n",
       " 100,\n",
       " 619,\n",
       " 28535,\n",
       " 28508,\n",
       " 100,\n",
       " 624,\n",
       " 28531,\n",
       " 28518,\n",
       " 28516,\n",
       " 28531,\n",
       " 28524,\n",
       " 626,\n",
       " 28537,\n",
       " 28526,\n",
       " 28531,\n",
       " 28511,\n",
       " 28515,\n",
       " 607,\n",
       " 28532,\n",
       " 28523,\n",
       " 28531,\n",
       " 608,\n",
       " 28523,\n",
       " 28531,\n",
       " 635,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 607,\n",
       " 28533,\n",
       " 100,\n",
       " 616,\n",
       " 28524,\n",
       " 610,\n",
       " 28522,\n",
       " 28510,\n",
       " 28524,\n",
       " 100,\n",
       " 100,\n",
       " 607,\n",
       " 28536,\n",
       " 619,\n",
       " 28532,\n",
       " 28525,\n",
       " 28533,\n",
       " 635,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 607,\n",
       " 28535,\n",
       " 626,\n",
       " 28532,\n",
       " 28515,\n",
       " 28531,\n",
       " 28524,\n",
       " 28536,\n",
       " 28508,\n",
       " 607,\n",
       " 28533,\n",
       " 100,\n",
       " 100,\n",
       " 616,\n",
       " 28531,\n",
       " 28518,\n",
       " 28535,\n",
       " 607,\n",
       " 28535,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 635,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 615,\n",
       " 28535,\n",
       " 100,\n",
       " 100,\n",
       " 607,\n",
       " 28524,\n",
       " 613,\n",
       " 28532,\n",
       " 28523,\n",
       " 28531,\n",
       " 610,\n",
       " 28532,\n",
       " 28529,\n",
       " 28529,\n",
       " 28535,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 615,\n",
       " 28534,\n",
       " 28510,\n",
       " 28529,\n",
       " 28531,\n",
       " 28518,\n",
       " 627,\n",
       " 28536,\n",
       " 626,\n",
       " 28510,\n",
       " 28515,\n",
       " 28531,\n",
       " 100,\n",
       " 635,\n",
       " 100,\n",
       " 615,\n",
       " 28535,\n",
       " 626,\n",
       " 28532,\n",
       " 28515,\n",
       " 28531,\n",
       " 28524,\n",
       " 28536,\n",
       " 28508,\n",
       " 607,\n",
       " 28533,\n",
       " 100,\n",
       " 616,\n",
       " 28531,\n",
       " 28518,\n",
       " 28535,\n",
       " 607,\n",
       " 28535,\n",
       " 100,\n",
       " 100,\n",
       " 610,\n",
       " 28531,\n",
       " 28518,\n",
       " 100,\n",
       " 619,\n",
       " 28535,\n",
       " 28508,\n",
       " 100,\n",
       " 102]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] टी20 वर्ल्ड कप जीतकर लौटने वाली टीम इंडिया का मुंबई में काफी शानदार स्वागत किया गया । इस दौरान मुंबई की सड़कों पर जमकर भीड़ देखने को मिली । फैंस टीम इंडिया के सितारों की एक झलक पाने के लिए उतावले थे । इस दौरान फैंस ने कुछ ऐसा कर दिया जिससे उन्हें खुद काफी नुकसान हो सकता था । फैंस ने सितारों की झलक पाने के लिए अपनी जान जोखिम में डाली [SEP]'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['टी',\n",
       " '##20',\n",
       " 'व',\n",
       " '##र',\n",
       " '##्ल',\n",
       " '##्ड',\n",
       " 'क',\n",
       " '##प',\n",
       " 'जी',\n",
       " '##त',\n",
       " '##कर',\n",
       " 'ल',\n",
       " '##ौ',\n",
       " '##टन',\n",
       " '##े',\n",
       " 'वाली',\n",
       " 'टीम',\n",
       " 'इंडिया',\n",
       " 'का',\n",
       " 'मुंबई',\n",
       " 'में',\n",
       " 'काफी',\n",
       " 'श',\n",
       " '##ान',\n",
       " '##दार',\n",
       " 'स',\n",
       " '##्व',\n",
       " '##ाग',\n",
       " '##त',\n",
       " 'किया',\n",
       " 'गया',\n",
       " '।',\n",
       " 'इस',\n",
       " 'दौरान',\n",
       " 'मुंबई',\n",
       " 'की',\n",
       " 'स',\n",
       " '##ड़',\n",
       " '##कों',\n",
       " 'पर',\n",
       " 'ज',\n",
       " '##म',\n",
       " '##कर',\n",
       " 'भी',\n",
       " '##ड़',\n",
       " 'दे',\n",
       " '##खने',\n",
       " 'को',\n",
       " 'म',\n",
       " '##िली',\n",
       " '।',\n",
       " 'फ',\n",
       " '##ैं',\n",
       " '##स',\n",
       " 'टीम',\n",
       " 'इंडिया',\n",
       " 'के',\n",
       " 'स',\n",
       " '##िता',\n",
       " '##रों',\n",
       " 'की',\n",
       " 'एक',\n",
       " 'झ',\n",
       " '##ल',\n",
       " '##क',\n",
       " 'प',\n",
       " '##ाने',\n",
       " 'के',\n",
       " 'लिए',\n",
       " 'उ',\n",
       " '##ता',\n",
       " '##वले',\n",
       " 'थे',\n",
       " '।',\n",
       " 'इस',\n",
       " 'दौरान',\n",
       " 'फ',\n",
       " '##ैं',\n",
       " '##स',\n",
       " 'ने',\n",
       " 'कुछ',\n",
       " 'ऐसा',\n",
       " 'कर',\n",
       " 'दिया',\n",
       " 'जिससे',\n",
       " 'उन्हें',\n",
       " 'ख',\n",
       " '##ु',\n",
       " '##द',\n",
       " 'काफी',\n",
       " 'न',\n",
       " '##ुक',\n",
       " '##सा',\n",
       " '##न',\n",
       " 'हो',\n",
       " 'सकता',\n",
       " 'था',\n",
       " '।',\n",
       " 'फ',\n",
       " '##ैं',\n",
       " '##स',\n",
       " 'ने',\n",
       " 'स',\n",
       " '##िता',\n",
       " '##रों',\n",
       " 'की',\n",
       " 'झ',\n",
       " '##ल',\n",
       " '##क',\n",
       " 'प',\n",
       " '##ाने',\n",
       " 'के',\n",
       " 'लिए',\n",
       " 'अपनी',\n",
       " 'जा',\n",
       " '##न',\n",
       " 'जो',\n",
       " '##ख',\n",
       " '##िम',\n",
       " 'में',\n",
       " 'ड',\n",
       " '##ाली']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hin.encode("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-cased\")\n",
    "\n",
    "# Push the tokenizer to your namespace with the name \"my-finetuned-bert\".\n",
    "tokenizer.push_to_hub(\"my-finetuned-bert\")\n",
    "\n",
    "# Push the tokenizer to an organization with the name \"my-finetuned-bert\".\n",
    "tokenizer.push_to_hub(\"huggingface/my-finetuned-bert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[UNK]',\n",
       " '[UNK]',\n",
       " 'क',\n",
       " '##प',\n",
       " 'ज',\n",
       " '##ी',\n",
       " '##त',\n",
       " '##क',\n",
       " '##र',\n",
       " '[UNK]',\n",
       " 'व',\n",
       " '##ा',\n",
       " '##ल',\n",
       " '##ी',\n",
       " '[UNK]',\n",
       " '[UNK]',\n",
       " 'क',\n",
       " '##ा',\n",
       " '[UNK]',\n",
       " 'म',\n",
       " '##े',\n",
       " '##ं',\n",
       " '[UNK]',\n",
       " 'श',\n",
       " '##ा',\n",
       " '##न',\n",
       " '##द',\n",
       " '##ा',\n",
       " '##र',\n",
       " 'स',\n",
       " '##्',\n",
       " '##व',\n",
       " '##ा',\n",
       " '##ग',\n",
       " '##त',\n",
       " 'क',\n",
       " '##ि',\n",
       " '##य',\n",
       " '##ा',\n",
       " 'ग',\n",
       " '##य',\n",
       " '##ा',\n",
       " '।',\n",
       " '[UNK]',\n",
       " '[UNK]',\n",
       " '[UNK]',\n",
       " 'क',\n",
       " '##ी',\n",
       " '[UNK]',\n",
       " 'प',\n",
       " '##र',\n",
       " 'ज',\n",
       " '##म',\n",
       " '##क',\n",
       " '##र',\n",
       " '[UNK]',\n",
       " '[UNK]',\n",
       " 'क',\n",
       " '##ो',\n",
       " 'म',\n",
       " '##ि',\n",
       " '##ल',\n",
       " '##ी',\n",
       " '।',\n",
       " '[UNK]',\n",
       " '[UNK]',\n",
       " '[UNK]',\n",
       " 'क',\n",
       " '##े',\n",
       " 'स',\n",
       " '##ि',\n",
       " '##त',\n",
       " '##ा',\n",
       " '##र',\n",
       " '##ो',\n",
       " '##ं',\n",
       " 'क',\n",
       " '##ी',\n",
       " '[UNK]',\n",
       " '[UNK]',\n",
       " 'प',\n",
       " '##ा',\n",
       " '##न',\n",
       " '##े',\n",
       " 'क',\n",
       " '##े',\n",
       " '[UNK]',\n",
       " '[UNK]',\n",
       " '[UNK]',\n",
       " '।',\n",
       " '[UNK]',\n",
       " '[UNK]',\n",
       " '[UNK]',\n",
       " 'न',\n",
       " '##े',\n",
       " '[UNK]',\n",
       " '[UNK]',\n",
       " 'क',\n",
       " '##र',\n",
       " 'द',\n",
       " '##ि',\n",
       " '##य',\n",
       " '##ा',\n",
       " 'ज',\n",
       " '##ि',\n",
       " '##स',\n",
       " '##स',\n",
       " '##े',\n",
       " '[UNK]',\n",
       " '[UNK]',\n",
       " '[UNK]',\n",
       " 'न',\n",
       " '##ु',\n",
       " '##क',\n",
       " '##स',\n",
       " '##ा',\n",
       " '##न',\n",
       " 'ह',\n",
       " '##ो',\n",
       " 'स',\n",
       " '##क',\n",
       " '##त',\n",
       " '##ा',\n",
       " '[UNK]',\n",
       " '।',\n",
       " '[UNK]',\n",
       " 'न',\n",
       " '##े',\n",
       " 'स',\n",
       " '##ि',\n",
       " '##त',\n",
       " '##ा',\n",
       " '##र',\n",
       " '##ो',\n",
       " '##ं',\n",
       " 'क',\n",
       " '##ी',\n",
       " '[UNK]',\n",
       " 'प',\n",
       " '##ा',\n",
       " '##न',\n",
       " '##े',\n",
       " 'क',\n",
       " '##े',\n",
       " '[UNK]',\n",
       " '[UNK]',\n",
       " 'ज',\n",
       " '##ा',\n",
       " '##न',\n",
       " '[UNK]',\n",
       " 'म',\n",
       " '##े',\n",
       " '##ं',\n",
       " '[UNK]']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(\"टी20 वर्ल्ड कप जीतकर लौटने वाली टीम इंडिया का मुंबई में काफी शानदार स्वागत किया गया। इस दौरान मुंबई की सड़कों पर जमकर भीड़ देखने को मिली। फैंस टीम इंडिया के सितारों की एक झलक पाने के लिए उतावले थे। इस दौरान फैंस ने कुछ ऐसा कर दिया जिससे उन्हें खुद काफी नुकसान हो सकता था। फैंस ने सितारों की झलक पाने के लिए अपनी जान जोखिम में डाली\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28996"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SPECIAL_TOKENS_ATTRIBUTES',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_add_tokens',\n",
       " '_additional_special_tokens',\n",
       " '_auto_class',\n",
       " '_batch_encode_plus',\n",
       " '_bos_token',\n",
       " '_call_one',\n",
       " '_cls_token',\n",
       " '_compile_jinja_template',\n",
       " '_convert_encoding',\n",
       " '_convert_id_to_token',\n",
       " '_convert_token_to_id_with_added_voc',\n",
       " '_create_repo',\n",
       " '_decode',\n",
       " '_decode_use_source_tokenizer',\n",
       " '_encode_plus',\n",
       " '_eos_token',\n",
       " '_eventual_warn_about_too_long_sequence',\n",
       " '_eventually_correct_t5_max_length',\n",
       " '_from_pretrained',\n",
       " '_get_files_timestamps',\n",
       " '_get_padding_truncation_strategies',\n",
       " '_in_target_context_manager',\n",
       " '_mask_token',\n",
       " '_pad',\n",
       " '_pad_token',\n",
       " '_pad_token_type_id',\n",
       " '_processor_class',\n",
       " '_save_pretrained',\n",
       " '_sep_token',\n",
       " '_set_processor_class',\n",
       " '_switch_to_input_mode',\n",
       " '_switch_to_target_mode',\n",
       " '_tokenizer',\n",
       " '_unk_token',\n",
       " '_upload_modified_files',\n",
       " 'add_special_tokens',\n",
       " 'add_tokens',\n",
       " 'added_tokens_decoder',\n",
       " 'added_tokens_encoder',\n",
       " 'additional_special_tokens',\n",
       " 'additional_special_tokens_ids',\n",
       " 'all_special_ids',\n",
       " 'all_special_tokens',\n",
       " 'all_special_tokens_extended',\n",
       " 'apply_chat_template',\n",
       " 'as_target_tokenizer',\n",
       " 'backend_tokenizer',\n",
       " 'batch_decode',\n",
       " 'batch_encode_plus',\n",
       " 'bos_token',\n",
       " 'bos_token_id',\n",
       " 'build_inputs_with_special_tokens',\n",
       " 'can_save_slow_tokenizer',\n",
       " 'chat_template',\n",
       " 'clean_up_tokenization',\n",
       " 'clean_up_tokenization_spaces',\n",
       " 'cls_token',\n",
       " 'cls_token_id',\n",
       " 'convert_added_tokens',\n",
       " 'convert_ids_to_tokens',\n",
       " 'convert_tokens_to_ids',\n",
       " 'convert_tokens_to_string',\n",
       " 'create_token_type_ids_from_sequences',\n",
       " 'decode',\n",
       " 'decoder',\n",
       " 'default_chat_template',\n",
       " 'deprecation_warnings',\n",
       " 'do_lower_case',\n",
       " 'encode',\n",
       " 'encode_plus',\n",
       " 'eos_token',\n",
       " 'eos_token_id',\n",
       " 'from_pretrained',\n",
       " 'get_added_vocab',\n",
       " 'get_special_tokens_mask',\n",
       " 'get_vocab',\n",
       " 'init_inputs',\n",
       " 'init_kwargs',\n",
       " 'is_fast',\n",
       " 'mask_token',\n",
       " 'mask_token_id',\n",
       " 'max_len_sentences_pair',\n",
       " 'max_len_single_sentence',\n",
       " 'model_input_names',\n",
       " 'model_max_length',\n",
       " 'name_or_path',\n",
       " 'num_special_tokens_to_add',\n",
       " 'pad',\n",
       " 'pad_token',\n",
       " 'pad_token_id',\n",
       " 'pad_token_type_id',\n",
       " 'padding_side',\n",
       " 'prepare_for_model',\n",
       " 'prepare_seq2seq_batch',\n",
       " 'pretrained_vocab_files_map',\n",
       " 'push_to_hub',\n",
       " 'register_for_auto_class',\n",
       " 'sanitize_special_tokens',\n",
       " 'save_pretrained',\n",
       " 'save_vocabulary',\n",
       " 'sep_token',\n",
       " 'sep_token_id',\n",
       " 'set_truncation_and_padding',\n",
       " 'slow_tokenizer_class',\n",
       " 'special_tokens_map',\n",
       " 'special_tokens_map_extended',\n",
       " 'split_special_tokens',\n",
       " 'tokenize',\n",
       " 'train_new_from_iterator',\n",
       " 'truncate_sequences',\n",
       " 'truncation_side',\n",
       " 'unk_token',\n",
       " 'unk_token_id',\n",
       " 'verbose',\n",
       " 'vocab',\n",
       " 'vocab_files_names',\n",
       " 'vocab_size']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28996"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vocab_file': 'vocab.txt', 'tokenizer_file': 'tokenizer.json'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_files_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[2.4389e-01, 9.9934e-01, 5.8120e-01,  ..., 3.2883e-02,\n",
      "          3.8624e-01, 2.2267e-01],\n",
      "         [4.4363e-01, 1.3324e-01, 6.2764e-01,  ..., 7.6594e-01,\n",
      "          4.0209e-01, 1.9251e-01],\n",
      "         [4.3578e-01, 1.7083e-01, 7.6945e-01,  ..., 6.6378e-01,\n",
      "          6.0378e-01, 5.4441e-01],\n",
      "         ...,\n",
      "         [3.7827e-01, 8.2754e-01, 7.2267e-01,  ..., 2.1232e-01,\n",
      "          7.3114e-01, 8.4807e-01],\n",
      "         [9.5113e-02, 6.7128e-01, 1.9636e-01,  ..., 7.5465e-01,\n",
      "          1.5344e-01, 5.9019e-01],\n",
      "         [3.0075e-02, 7.9916e-01, 4.9934e-01,  ..., 8.5592e-01,\n",
      "          6.6930e-01, 3.5631e-01]],\n",
      "\n",
      "        [[8.0079e-01, 7.2917e-01, 2.2525e-02,  ..., 9.4114e-01,\n",
      "          9.9348e-01, 5.4295e-02],\n",
      "         [5.2764e-01, 8.0727e-01, 6.2938e-01,  ..., 6.8766e-01,\n",
      "          8.5788e-01, 7.7981e-01],\n",
      "         [1.0472e-01, 4.3805e-01, 6.8010e-01,  ..., 6.3962e-01,\n",
      "          6.6393e-01, 1.1014e-01],\n",
      "         ...,\n",
      "         [9.2923e-01, 9.7174e-01, 6.2213e-01,  ..., 2.3156e-01,\n",
      "          5.5514e-02, 9.7109e-01],\n",
      "         [8.2415e-02, 2.1453e-01, 5.4803e-01,  ..., 5.8469e-01,\n",
      "          2.5305e-01, 1.4758e-01],\n",
      "         [4.9827e-02, 1.7736e-01, 2.8561e-01,  ..., 9.4348e-01,\n",
      "          9.3612e-01, 3.5053e-01]],\n",
      "\n",
      "        [[4.1820e-01, 6.5073e-01, 6.7387e-02,  ..., 9.3816e-01,\n",
      "          8.1305e-02, 8.0309e-01],\n",
      "         [5.1385e-01, 4.4569e-01, 4.6141e-01,  ..., 7.2574e-01,\n",
      "          7.2261e-01, 9.0351e-01],\n",
      "         [3.1543e-01, 3.9725e-01, 4.8198e-01,  ..., 4.1321e-01,\n",
      "          1.3819e-01, 8.5367e-01],\n",
      "         ...,\n",
      "         [7.5042e-01, 5.4225e-01, 5.3070e-02,  ..., 7.6831e-01,\n",
      "          9.1721e-01, 7.0971e-01],\n",
      "         [5.5729e-01, 9.3787e-01, 1.0229e-02,  ..., 8.7772e-01,\n",
      "          9.3929e-01, 5.8387e-03],\n",
      "         [6.1696e-01, 1.9188e-01, 7.9151e-01,  ..., 5.8678e-01,\n",
      "          3.6193e-02, 5.7288e-03]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.9915e-01, 9.0262e-01, 4.1200e-02,  ..., 3.6695e-01,\n",
      "          1.4633e-01, 1.4441e-01],\n",
      "         [4.5902e-01, 9.2740e-01, 4.0646e-03,  ..., 5.3009e-01,\n",
      "          4.2569e-01, 5.0860e-01],\n",
      "         [3.1099e-01, 1.5399e-01, 9.0117e-01,  ..., 6.1694e-01,\n",
      "          8.3984e-01, 3.0762e-01],\n",
      "         ...,\n",
      "         [8.3176e-01, 2.2963e-01, 7.4696e-01,  ..., 9.4074e-04,\n",
      "          9.7769e-02, 8.2029e-01],\n",
      "         [6.1327e-01, 8.9978e-01, 1.5521e-01,  ..., 5.4468e-01,\n",
      "          1.0699e-01, 4.7580e-01],\n",
      "         [2.1445e-01, 9.1415e-01, 4.6998e-02,  ..., 5.1199e-02,\n",
      "          1.2939e-01, 8.8573e-02]],\n",
      "\n",
      "        [[3.8776e-01, 8.4522e-01, 7.1344e-01,  ..., 9.5005e-01,\n",
      "          3.4306e-01, 9.3507e-01],\n",
      "         [5.7835e-02, 4.1765e-01, 8.0832e-01,  ..., 6.5555e-01,\n",
      "          2.6710e-01, 5.7769e-01],\n",
      "         [6.7285e-01, 3.3963e-01, 6.7885e-01,  ..., 5.7295e-01,\n",
      "          1.6929e-01, 2.3711e-01],\n",
      "         ...,\n",
      "         [6.0844e-01, 2.3136e-01, 5.4625e-01,  ..., 9.2885e-01,\n",
      "          8.8318e-01, 1.7443e-01],\n",
      "         [1.9351e-01, 5.4948e-02, 5.4897e-01,  ..., 9.4103e-01,\n",
      "          8.4119e-01, 2.9978e-01],\n",
      "         [2.4442e-01, 8.4722e-01, 3.4649e-01,  ..., 8.2470e-01,\n",
      "          3.4485e-01, 7.5776e-01]],\n",
      "\n",
      "        [[3.1415e-01, 5.4556e-02, 8.0480e-01,  ..., 3.2000e-02,\n",
      "          5.6214e-01, 9.5148e-02],\n",
      "         [2.6575e-01, 8.3924e-01, 1.2118e-02,  ..., 3.1840e-01,\n",
      "          4.9651e-02, 9.2416e-02],\n",
      "         [7.9693e-01, 9.8897e-01, 4.8796e-01,  ..., 3.7337e-01,\n",
      "          1.7208e-01, 8.1646e-01],\n",
      "         ...,\n",
      "         [7.0588e-01, 4.4105e-01, 7.9642e-01,  ..., 5.0500e-01,\n",
      "          9.3932e-01, 2.2285e-01],\n",
      "         [3.4870e-01, 9.7869e-01, 6.8617e-01,  ..., 5.1410e-01,\n",
      "          6.0824e-01, 2.9915e-01],\n",
      "         [8.1111e-01, 8.7490e-01, 8.4501e-01,  ..., 4.0576e-02,\n",
      "          5.6728e-01, 7.1477e-01]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create a random tensor of size (32, 512, 64) with values from a uniform distribution\n",
    "random_tensor = torch.rand(32, 512, 64)\n",
    "\n",
    "print(random_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 512, 64])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4557, 0.4555, 0.4623,  ..., 0.5218, 0.5288, 0.5052],\n",
       "        [0.5422, 0.4675, 0.5210,  ..., 0.5028, 0.4792, 0.4816],\n",
       "        [0.5538, 0.4657, 0.4767,  ..., 0.5809, 0.4994, 0.4191],\n",
       "        ...,\n",
       "        [0.4831, 0.5221, 0.4784,  ..., 0.5474, 0.4724, 0.4819],\n",
       "        [0.5093, 0.4988, 0.4657,  ..., 0.5025, 0.4853, 0.4703],\n",
       "        [0.4731, 0.4723, 0.4725,  ..., 0.5648, 0.4904, 0.5949]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.mean(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_data=[[1,2,3],[4,5,6]]\n",
    "x=torch.tensor(list_data).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.5000, 3.5000, 4.5000]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.mean(dim=0, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.mean(dim=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 5.])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.mean(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A:\n",
    "    def __init__(self, a, b): \n",
    "        self.a = a\n",
    "        self.b = b\n",
    "    @staticmethod\n",
    "    def hello():\n",
    "        print(\"How are you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How are you\n"
     ]
    }
   ],
   "source": [
    "A.hello()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "\n",
    "# Reference Link: https://www.youtube.com/watch?v=ISNdQcPhsts \n",
    "# Github: https://github.com/hkproj/pytorch-transformer \n",
    "\n",
    "\n",
    "\n",
    "# Embedding\n",
    "class InputEmbeddings(nn.Module):\n",
    "    def __init__(self, d_model: int, vocab_size: int):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.vocab_size = vocab_size \n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.embedding(x)*math.sqrt(self.d_model)\n",
    "                              \n",
    "\n",
    "\n",
    "# Positional Embedding \n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self,d_model: int, seq_len: int, dropout: float) -> None: \n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.seq_len = seq_len \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # Create a matrix of shape (seq_len, d_model)\n",
    "        pe = torch.zeros(seq_len, d_model)\n",
    "\n",
    "        # creata a vector of shape (seq_len)\n",
    "        position = torch.arange(0, seq_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0,d_model,2).float()*(-math.log(10000.0)/d_model))\n",
    "        # Apply the sin to even position \n",
    "        pe[:, 0::2] = torch.sin(position*div_term)\n",
    "        pe[:,1::2] = torch.cos(position*div_term)\n",
    "        pe = pe.unsqueeze(0)  # (1, seq_len, d_model)\n",
    "\n",
    "        self.register_buffer('pe',pe) # Saved along with the model  (Along with the file)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = x + (self.pe[:, x.shape[1],:]).requries_grad_(False)  # It is not as a Trainable parameter\n",
    "        return self.dropout(x)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    " # Layer Normalization \n",
    "class LayerNormalization(nn.Module):\n",
    "    def __init__(self, eps:float=10**-6) -> None:\n",
    "        \"\"\"\n",
    "        X = X_normalized*gamma + bias\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.gamma = nn.Parameter(torch.ones(1))  # Make it learnable parameter \n",
    "        self.bias = nn.Parameter(torch.zeros(1)) # Added ( This is bias term) \n",
    "\n",
    "    def forward(self,x):\n",
    "        mean = x.mean(dim = -1, keepdim=True)\n",
    "        std = x.std(dim = -1, keepdim= True)\n",
    "        return self.gamma*(x-mean)/(std+self.eps) + self.bias\n",
    "     \n",
    "# Feed Forward Block \n",
    "class FeedForwardBlock(nn.Module):\n",
    "    def __init__(self, d_model: int, d_ff: int, dropout: float ) -> None:\n",
    "        super().__init__()\n",
    "        self.linear_1 = nn.Linear(d_model, d_ff)  # W1 and B1 \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.Linear_2=nn.Linear(d_ff, d_model) # W2 and B2 \n",
    "\n",
    "    def forward(self,x):\n",
    "        # (Batch, Seq_Leln, d_model) --> (Batch, Seq_Len, d_ff) ---> (Batch, Seq_Len, d_model)\n",
    "        x = self.linear_1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear_2(x)\n",
    "        return x \n",
    "\n",
    "\n",
    "# MultiHead Attention: \n",
    "class MultiHeadAttentionBlock(nn.Module):\n",
    "    def __init__(self,d_model:int, h: int, dropout: float)->None:\n",
    "        super().__init__()\n",
    "        self.d_model = d_model \n",
    "        self.h = h \n",
    "        assert d_model % h ==0, \"d_model is not divisible by h i.e number of heads\"\n",
    "\n",
    "        self.d_k = d_model//h \n",
    "        self.w_q = nn.Linear(d_model, d_model) # Wq\n",
    "        self.w_k = nn.Linear(d_model, d_model) # Wk\n",
    "        self.w_v = nn.Linear(d_model, d_model) # Wv\n",
    "        self.w_o = nn.Linear(d_model, d_model) # Wo\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def attention(query, key, value, mask, dropout: nn.Dropout):\n",
    "        d_k = query.shape[-1]\n",
    "\n",
    "        # ( Batch, h, seq_len, d_k) --> (Batch, h, seq_len, seq_len)\n",
    "        attention_scores = (query @ key.transpose(-2,-1))\n",
    "        if mask is not None: \n",
    "            attention_scores.masked_fill_(mask ==0, -1e9)\n",
    "        attention_scores = attention_scores.softmax(dim = -1 )  # (Batch, h, seq_len, seq_len)\n",
    "        if dropout is not None: \n",
    "            attention_scores = dropout(attention_scores)\n",
    "        return (attention_scores @ value), attention_scores\n",
    "\n",
    "\n",
    "    def forward(self, q, k, v, mask):\n",
    "        \"\"\" \n",
    "        If we don't want any word to interact with other word then we can mask them\n",
    "        \"\"\"\n",
    "        query = self.w_q(q)  #  (Batch, Seq_Len, d_model ) --> (Batch, Seq_Len, d_model)\n",
    "        key = self.w_k(k)  #  (Batch, Seq_Len, d_model ) --> (Batch, Seq_Len, d_model)\n",
    "        value = self.w_v(v) #  (Batch, Seq_Len, d_model ) --> (Batch, Seq_Len, d_model)\n",
    "\n",
    "        # (Batch, Seq_Len, d_model) --View--> (Batch, Seq_Len, h, d_k) ---Transpose-> (Batch, h, Seq_Len, d_k)\n",
    "        query = query.view(query.shape[0],query.shape[1],self.h, self.d_k).transpose(1,2)\n",
    "        key = query.view(query.shape[0],query.shape[1],self.h, self.d_k).transpose(1,2)\n",
    "        value = query.view(value.shape[0],value.shape[1], self.h, self.d_k).transpose(1,2)\n",
    "\n",
    "        x, self.attention_scores = MultiHeadAttentionBlock.attention(query, key, value, mask, self.dropout)\n",
    "\n",
    "        # (Batch, h, seq_len, d_k) --Transpose--> (Batch, Seq_Len, h, d_k) ---> (Batch, seq_len, d_model)\n",
    "\n",
    "        x = x.transpose(1,2).contiguous().view(x.shape[0], -1, self.h * self.d_k)\n",
    "\n",
    "        # (Batch, Seq_Len, d_model) --> (Batch, Seq_Len, d_model)\n",
    "\n",
    "        return self.w_o(x)\n",
    "\n",
    "# Build Residual Connection \n",
    "\n",
    "class ResidualConnection(nn.Module):\n",
    "    \n",
    "    def __init__(self, dropout:float) -> None:\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.norm = LayerNormalization()\n",
    "    \n",
    "    def forward(self, x, sublayer):\n",
    "        return x + self.dropout(sublayer(self.norm(x)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class EncoderBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, self_attention_block: MultiHeadAttentionBlock, feed_forward_block: FeedForwardBlock, dropout:float ) -> None:\n",
    "        super().__init__()\n",
    "        self.self_attention_block = self_attention_block\n",
    "        self.feed_forward_block = feed_forward_block \n",
    "        self.residual_coonnections = nn.ModuleList([ResidualConnection(dropout) for _ in range(2)])\n",
    "    \n",
    "\n",
    "    def forward(self, x, src_mask):\n",
    "        \"\"\"\n",
    "        src_mask: Hide the interaction of padding words with other words\"\n",
    "        \"\"\"\n",
    "        x = self.residual_coonnections[0](x, lambda x: self.self_attention_block(x,x,x, src_mask))\n",
    "        x = self.residual_coonnections[1](x, lambda x: self.feed_forward_block)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, layers: nn.ModuleList) ->None:\n",
    "        super().__init__()\n",
    "        self.layers = layers \n",
    "        self.norm = LayerNormalization()\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return self.norm(x) \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "## ----Decoder Block -------------\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, self_attention_block: MultiHeadAttentionBlock, cross_attention_block: MultiHeadAttentionBlock, feed_forward_block:FeedForwardBlock, dropout:float) -> None: \n",
    "        super().__init__()\n",
    "        self.self_attention_block = self_attention_block\n",
    "        self.cross_attention_block = cross_attention_block \n",
    "        self.feed_forward_block = feed_forward_block\n",
    "        self.residual_connections = nn.ModuleList([ResidualConnection(dropout) for _ in range(3)])\n",
    "\n",
    "\n",
    "    def forward(self, x, encoder_output, src_mask, tgt_mask):\n",
    "        x = self.residual_connections[0](x, lambda x: self.self_attention_block(x,x,x,tgt_mask))\n",
    "        x = self.residual_connections[1](x, lambda x: self.cross_attention_block(x,encoder_output, encoder_output, src_mask))\n",
    "        x = self.residual_connections[2](x, self.feed_forward_block)\n",
    "        return x \n",
    "    \n",
    "\n",
    "\n",
    "## Repeat Decoder block n-times \n",
    "\n",
    "class Decoder(nn.Module): \n",
    "\n",
    "    def __init__(self, layers: nn.ModuleList) ->  None: \n",
    "        super().__init__()\n",
    "        self.layers = layers \n",
    "        self.norm = LayerNormalization()\n",
    "\n",
    "    def forward(self, x, encoder_output, src_mask, tgt_mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, encoder_output, src_mask, tgt_mask)\n",
    "        return self.norm(x)\n",
    "\n",
    "\n",
    "# Projection Layear \n",
    "class ProjectionLayer(nn.Module):\n",
    "    def __init__(self, d_model:int, vocab_size: int) -> None: \n",
    "        super().__init__()\n",
    "        self.proj = nn.Linear(d_model, vocab_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # (Batch, seq_len, d_model) -->(Batch, seq_len, vocab_size) \n",
    "\n",
    "        return torch.log_softmax(self.proj(x),dim = -1)  # log_softmax for numerical stability \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# Define Transformer Block \n",
    "\n",
    "class Transformer(nn.Module):\n",
    "\n",
    "    def __init__(self, encoder: Encoder, decoder: Decoder, src_embed: InputEmbeddings, tgt_embed: InputEmbeddings, src_pos:PositionalEncoding, tgt_pos:PositionalEncoding, projection_layer:ProjectionLayer) -> None:\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder \n",
    "        self.src_embed = src_embed\n",
    "        self.tgt_embed = tgt_embed\n",
    "        self.src_pos = src_pos \n",
    "        self.tgt_pos = tgt_pos \n",
    "        self.projection_layer = projection_layer\n",
    "    \n",
    "    def encode(self, src, src_mask):\n",
    "        src = self.src_embed(src)\n",
    "        src = self.src_pos(src)\n",
    "        return self.encoder(src, src_mask)\n",
    "    \n",
    "    def decode(self, encoder_ouptut, src_mask, tgt, tgt_mask):\n",
    "        tgt = self.tgt_embed(tgt)\n",
    "        tgt = self.tgt_pos(tgt)\n",
    "        return self.decoder(tgt, encoder_ouptut, src_mask, tgt_mask)\n",
    "\n",
    "    def project(self, x): \n",
    "        return self.projection_layer(x)\n",
    "\n",
    "# Initialize the transformer\n",
    "def build_transformer(src_vocab_size:int, tgt_vocab_size: int, src_seq_len:int, tgt_seq_len:int,d_model: int =512, N: int =6 , h: int = 8, dropout:float = 0.1, d_ff: int =2048):\n",
    "    # Create the embdeeing layers \n",
    "    src_embed = InputEmbeddings(d_model, src_vocab_size)\n",
    "    tgt_embed = InputEmbeddings(d_model, tgt_vocab_size)\n",
    "\n",
    "    # Create the Positional Encoding \n",
    "    src_pos = PositionalEncoding(d_model, src_seq_len, dropout)\n",
    "    tgt_pos = PositionalEncoding(d_model, tgt_seq_len, dropout)\n",
    "\n",
    "    # Create the encoder blocks\n",
    "    encoder_blocks =[]\n",
    "\n",
    "    for _ in range(N):\n",
    "        encoder_self_attention_block = MultiHeadAttentionBlock(d_model, h, dropout)\n",
    "        feed_forward_block = FeedForwardBlock(d_model, d_ff, dropout)\n",
    "        encoder_block = EncoderBlock(encoder_self_attention_block, feed_forward_block, dropout)\n",
    "        encoder_blocks.append(encoder_block)\n",
    "\n",
    "    # Create the decoder blocks \n",
    "    decoder_blocks = [] \n",
    "    for _ in range(N):\n",
    "        decoder_self_attention_block = MultiHeadAttentionBlock(d_model, h, dropout)\n",
    "        decoder_cross_attention_block = MultiHeadAttentionBlock(d_model, h, dropout)\n",
    "        feed_forward_block = FeedForwardBlock(d_model, d_ff, dropout)\n",
    "        decoder_block = DecoderBlock(decoder_self_attention_block,decoder_cross_attention_block, feed_forward_block, dropout)\n",
    "        decoder_blocks.append(decoder_block)\n",
    "    \n",
    "    # Create Encoer and the Decoder Block \n",
    "\n",
    "    encoder = Encoder(nn.ModuleList(encoder_blocks))\n",
    "    decoder = Decoder(nn.ModuleList(decoder_blocks))\n",
    "\n",
    "    # Create the projection Layer \n",
    "\n",
    "    projection_layer = ProjectionLayer(d_model, tgt_vocab_size)\n",
    "\n",
    "    # Create the transformer \n",
    "    transformer = Transformer(encoder, decoder, src_embed, tgt_embed, src_pos, tgt_pos, projection_layer)\n",
    "\n",
    "    # Initialize the parameters \n",
    "    for p in transformer.parameters():\n",
    "        if p.dim() > 1: \n",
    "            nn.init.xavier_uniform_(p) \n",
    "    return transformer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab_size=100000\n",
    "tgt_vocab_size=280000\n",
    "src_seq_len=100\n",
    "tgt_seq_len=150\n",
    "d_model=64\n",
    "N=6 \n",
    "h= 8\n",
    "dropout = 0.1\n",
    "d_ff=2048\n",
    "trans=build_transformer(src_vocab_size, tgt_vocab_size, src_seq_len, tgt_seq_len,d_model, N , h, dropout, d_ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (encoder): Encoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x EncoderBlock(\n",
       "        (self_attention_block): MultiHeadAttentionBlock(\n",
       "          (w_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (w_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (w_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (w_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward_block): FeedForwardBlock(\n",
       "          (linear_1): Linear(in_features=64, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (Linear_2): Linear(in_features=2048, out_features=64, bias=True)\n",
       "        )\n",
       "        (residual_coonnections): ModuleList(\n",
       "          (0-1): 2 x ResidualConnection(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (norm): LayerNormalization()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNormalization()\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x DecoderBlock(\n",
       "        (self_attention_block): MultiHeadAttentionBlock(\n",
       "          (w_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (w_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (w_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (w_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (cross_attention_block): MultiHeadAttentionBlock(\n",
       "          (w_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (w_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (w_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (w_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward_block): FeedForwardBlock(\n",
       "          (linear_1): Linear(in_features=64, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (Linear_2): Linear(in_features=2048, out_features=64, bias=True)\n",
       "        )\n",
       "        (residual_connections): ModuleList(\n",
       "          (0-2): 3 x ResidualConnection(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (norm): LayerNormalization()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNormalization()\n",
       "  )\n",
       "  (src_embed): InputEmbeddings(\n",
       "    (embedding): Embedding(100000, 64)\n",
       "  )\n",
       "  (tgt_embed): InputEmbeddings(\n",
       "    (embedding): Embedding(280000, 64)\n",
       "  )\n",
       "  (src_pos): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (tgt_pos): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (projection_layer): ProjectionLayer(\n",
       "    (proj): Linear(in_features=64, out_features=280000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of Transformer(\n",
       "  (encoder): Encoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x EncoderBlock(\n",
       "        (self_attention_block): MultiHeadAttentionBlock(\n",
       "          (w_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (w_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (w_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (w_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward_block): FeedForwardBlock(\n",
       "          (linear_1): Linear(in_features=64, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (Linear_2): Linear(in_features=2048, out_features=64, bias=True)\n",
       "        )\n",
       "        (residual_coonnections): ModuleList(\n",
       "          (0-1): 2 x ResidualConnection(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (norm): LayerNormalization()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNormalization()\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x DecoderBlock(\n",
       "        (self_attention_block): MultiHeadAttentionBlock(\n",
       "          (w_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (w_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (w_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (w_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (cross_attention_block): MultiHeadAttentionBlock(\n",
       "          (w_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (w_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (w_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (w_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward_block): FeedForwardBlock(\n",
       "          (linear_1): Linear(in_features=64, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (Linear_2): Linear(in_features=2048, out_features=64, bias=True)\n",
       "        )\n",
       "        (residual_connections): ModuleList(\n",
       "          (0-2): 3 x ResidualConnection(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (norm): LayerNormalization()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNormalization()\n",
       "  )\n",
       "  (src_embed): InputEmbeddings(\n",
       "    (embedding): Embedding(100000, 64)\n",
       "  )\n",
       "  (tgt_embed): InputEmbeddings(\n",
       "    (embedding): Embedding(280000, 64)\n",
       "  )\n",
       "  (src_pos): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (tgt_pos): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (projection_layer): ProjectionLayer(\n",
       "    (proj): Linear(in_features=64, out_features=280000, bias=True)\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputEmbeddings(nn.Module):\n",
    "    def __init__(self, d_model: int, vocab_size: int):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.vocab_size = vocab_size \n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.embedding(x)*math.sqrt(self.d_model)\n",
    "                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb=InputEmbeddings(d_model=64,vocab_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.tensor(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 64])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb(torch.tensor([[10],[20],[3]])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.tensor([[10],[20],[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10],\n",
       "        [20],\n",
       "        [ 3]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[[1,2,3],[4,5,6],[7,8,9],[10,5,6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.tensor(x).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.mean(dim = 0, keepdim=True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.],\n",
       "        [5.],\n",
       "        [8.],\n",
       "        [7.]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.mean(dim = -1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model =3\n",
    "a=nn.Linear(d_model, d_ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2048, 3])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.tensor([[[1,2,3],[4,5,6],[7,8,9]], [[1,2,3],[4,5,6],[7,8,9]]]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 2048])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, BertForSequenceClassification\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"AkshatSurolia/ICD-10-Code-Prediction\")\n",
    "model = BertForSequenceClassification.from_pretrained(\"AkshatSurolia/ICD-10-Code-Prediction\")\n",
    "config = model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"IMMUNIZATION ADMINISTRATION (INCLUDES PERCUTANEOUS, INTRADERMAL, SUBCUTANEOUS,OR INTRAMUSCULAR INJECTIONS); 1 VACCINE (SINGLE OR COMBINATION VACCINE/TOXOID)\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[-0.2510,  0.2822, -0.9486,  ..., -0.2305, -0.3414, -0.6066]],\n",
       "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = output.logits.detach().cpu().numpy()[0].argsort()[::-1][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9734,  2692, 12591,  9656,  9874])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['S00.86', 'G40.00', 'T45.93', 'R89.4', 'S05.51']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[config.id2label[ids] for ids in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultiHead Attention: \n",
    "class MultiHeadAttentionBlock(nn.Module):\n",
    "    def __init__(self,d_model:int, h: int, dropout: float)->None:\n",
    "        super().__init__()\n",
    "        self.d_model = d_model \n",
    "        self.h = h \n",
    "        assert d_model % h ==0, \"d_model is not divisible by h i.e number of heads\"\n",
    "\n",
    "        self.d_k = d_model//h \n",
    "        self.w_q = nn.Linear(d_model, d_model) # Wq\n",
    "        self.w_k = nn.Linear(d_model, d_model) # Wk\n",
    "        self.w_v = nn.Linear(d_model, d_model) # Wv\n",
    "        self.w_o = nn.Linear(d_model, d_model) # Wo\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def attention(query, key, value, mask, dropout: nn.Dropout):\n",
    "        d_k = query.shape[-1]\n",
    "\n",
    "        # ( Batch, h, seq_len, d_k) --> (Batch, h, seq_len, seq_len)\n",
    "        attention_scores = (query @ key.transpose(-2,-1))\n",
    "        if mask is not None: \n",
    "            attention_scores.masked_fill_(mask ==0, -1e9)\n",
    "        attention_scores = attention_scores.softmax(dim = -1 )  # (Batch, h, seq_len, seq_len)\n",
    "        if dropout is not None: \n",
    "            attention_scores = dropout(attention_scores)\n",
    "        return (attention_scores @ value), attention_scores\n",
    "\n",
    "\n",
    "    def forward(self, q, k, v, mask):\n",
    "        \"\"\" \n",
    "        If we don't want any word to interact with other word then we can mask them\n",
    "        \"\"\"\n",
    "        query = self.w_q(q)  #  (Batch, Seq_Len, d_model ) --> (Batch, Seq_Len, d_model)\n",
    "        key = self.w_k(k)  #  (Batch, Seq_Len, d_model ) --> (Batch, Seq_Len, d_model)\n",
    "        value = self.w_v(v) #  (Batch, Seq_Len, d_model ) --> (Batch, Seq_Len, d_model)\n",
    "\n",
    "        # (Batch, Seq_Len, d_model) --View--> (Batch, Seq_Len, h, d_k) ---Transpose-> (Batch, h, Seq_Len, d_k)\n",
    "        query = query.view(query.shape[0],query.shape[1],self.h, self.d_k).transpose(1,2)\n",
    "        key = key.view(key.shape[0],key.shape[1],self.h, self.d_k).transpose(1,2)\n",
    "        value = value.view(value.shape[0],value.shape[1], self.h, self.d_k).transpose(1,2)\n",
    "\n",
    "        x, self.attention_scores = MultiHeadAttentionBlock.attention(query, key, value, mask, self.dropout)\n",
    "\n",
    "        # (Batch, h, seq_len, d_k) --Transpose--> (Batch, Seq_Len, h, d_k) ---> (Batch, seq_len, d_model)\n",
    "\n",
    "        x = x.transpose(1,2).contiguous().view(x.shape[0], -1, self.h * self.d_k)\n",
    "\n",
    "        # (Batch, Seq_Len, d_model) --> (Batch, Seq_Len, d_model)\n",
    "\n",
    "        return self.w_o(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "h=MultiHeadAttentionBlock(128,4,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[[[i for i in range(0,128)],[i for i in range(0,128)],[i for i in range(0,128)]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.tensor(x).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.8514e+01,  1.3590e+01,  1.9115e+01, -8.1927e+00,  2.2603e+01,\n",
       "          -8.1634e+00,  1.5603e+01, -1.4543e+01,  4.2188e+01,  1.9583e+01,\n",
       "           4.2932e+01,  1.4161e+01,  3.6501e+01, -3.6716e+01, -3.1962e+01,\n",
       "          -2.6261e+01,  3.7146e+00, -2.5213e+01, -4.0339e+01,  1.4971e+01,\n",
       "           5.2246e+01,  3.8348e+01, -1.9493e+00,  9.3151e+00,  3.8483e+01,\n",
       "          -8.2403e+00,  2.2796e+01, -1.9584e+01, -9.6835e+00,  3.2506e+00,\n",
       "           5.6873e+00, -1.1017e+01,  2.5132e+01, -3.7777e+00,  1.0076e+01,\n",
       "          -2.5283e+01,  2.3744e+01,  7.1734e+00,  4.6779e+01,  3.0813e+01,\n",
       "          -2.1130e+01, -5.6546e+01, -3.7198e+00,  8.2197e+00,  2.9527e+01,\n",
       "           2.3327e+01, -1.7878e+01, -3.4118e+01, -1.5041e+01, -7.0320e+00,\n",
       "           1.4487e+01, -2.9288e+01,  4.8180e-01,  2.7899e+01, -1.0182e+01,\n",
       "           3.6482e+01,  4.7782e+00, -1.5621e+01,  1.8825e+01,  2.9894e+01,\n",
       "           2.7437e+00,  3.4271e+01, -2.5421e+01,  3.1532e+01,  9.2379e+00,\n",
       "           6.1850e+01, -4.1287e+01, -1.6209e+01,  5.0160e+01,  8.3628e+00,\n",
       "           2.8687e+00,  3.5768e+01, -3.2876e+01, -8.3786e+00, -2.1747e+01,\n",
       "           9.5480e+00, -2.7751e+00,  1.0066e+01,  1.2477e+00,  4.3032e+01,\n",
       "           7.6996e+00,  7.5628e+00,  5.2508e+01, -6.9622e+00, -3.7684e+00,\n",
       "           1.6043e+01, -5.5089e+01, -3.4280e+00, -1.9411e+01,  1.4385e+01,\n",
       "           3.6688e+01,  3.1146e+01, -4.3347e+01, -1.4093e+01, -3.9433e+01,\n",
       "          -3.6372e+01, -1.8427e+01,  9.2419e+00,  1.5157e+01,  4.8511e+00,\n",
       "          -1.8696e+01,  1.8879e+01, -2.5363e+01, -2.4185e+01,  9.2010e+00,\n",
       "           2.8746e+01,  1.6324e+01, -5.4907e+01, -2.1291e+01,  1.3162e+01,\n",
       "           2.7282e+00,  1.0252e+01,  1.9675e+01, -3.2960e+00,  8.1152e+00,\n",
       "           5.2017e+01, -3.8943e+01,  8.2250e+00, -4.9091e+01, -2.0309e+01,\n",
       "          -2.8219e+00,  3.9410e+01, -2.1029e+01,  5.1286e+01,  1.0205e+01,\n",
       "           2.3733e+01, -6.2492e+01, -1.0392e+01],\n",
       "         [-2.5981e+01,  1.2445e+01,  1.2135e+01, -3.5633e+00,  1.7235e+01,\n",
       "          -1.1306e+01,  1.3640e+01, -1.4352e+01,  3.1131e+01,  1.6466e+01,\n",
       "           3.3059e+01,  8.2025e+00,  2.9150e+01, -2.7445e+01, -2.0040e+01,\n",
       "          -2.0964e+01,  1.4412e+00, -2.1233e+01, -3.1906e+01,  1.7614e+00,\n",
       "           3.7211e+01,  3.0096e+01, -8.5973e-02,  4.3819e+00,  2.6960e+01,\n",
       "          -2.5845e+00,  1.4434e+01, -1.6659e+01, -9.6449e-01,  5.2200e+00,\n",
       "           4.3651e+00, -2.7442e+00,  2.1178e+01, -5.0553e+00,  1.2665e+01,\n",
       "          -1.6577e+01,  2.0775e+01,  3.9168e+00,  2.9763e+01,  2.2825e+01,\n",
       "          -1.6284e+01, -5.0129e+01, -5.1713e-01,  3.7901e+00,  2.0371e+01,\n",
       "           1.4989e+01, -1.3933e+01, -2.4886e+01, -7.4924e+00, -9.6587e-01,\n",
       "           1.1407e+01, -1.5950e+01,  4.1076e-01,  1.8980e+01, -5.8540e+00,\n",
       "           2.6109e+01,  2.8274e+00, -8.8819e+00,  2.2244e+01,  2.1466e+01,\n",
       "          -3.4830e+00,  2.2233e+01, -2.4963e+01,  2.3958e+01,  1.0783e+01,\n",
       "           4.5617e+01, -2.8485e+01, -9.5872e+00,  4.0708e+01,  7.2629e+00,\n",
       "           5.3644e+00,  3.0206e+01, -3.0573e+01,  1.5117e+00, -1.6346e+01,\n",
       "          -1.6109e+00, -3.4945e-01,  1.3692e+01, -9.8235e+00,  3.2251e+01,\n",
       "           4.6743e+00,  1.1489e+01,  3.7630e+01, -3.8694e+00, -2.9494e+00,\n",
       "           1.2514e+01, -4.6990e+01,  2.3468e+00, -1.5117e+01,  1.5866e+01,\n",
       "           2.8196e+01,  2.0301e+01, -3.0488e+01, -1.0363e+01, -3.5271e+01,\n",
       "          -2.9014e+01, -1.4030e+01,  8.5583e+00,  8.9911e+00,  1.9558e+00,\n",
       "          -1.6344e+01,  1.9409e+01, -2.0587e+01, -2.0005e+01,  6.6682e+00,\n",
       "           2.2901e+01,  1.5660e+01, -4.3968e+01, -1.0083e+01,  7.1664e+00,\n",
       "           2.9128e+00,  1.4489e+01,  1.7097e+01, -1.9900e+00,  8.9117e+00,\n",
       "           3.8534e+01, -3.5152e+01,  6.5902e+00, -3.8689e+01, -1.4726e+01,\n",
       "          -2.5704e+00,  2.8006e+01, -2.1511e+01,  3.6761e+01,  6.0638e+00,\n",
       "           1.8885e+01, -5.0340e+01, -1.1444e+01],\n",
       "         [-2.4246e+01,  1.5483e+01,  1.6533e+01, -7.0736e-01,  2.5405e+01,\n",
       "          -1.4239e+01,  1.8139e+01, -1.8148e+01,  3.6444e+01,  1.3823e+01,\n",
       "           3.6135e+01,  1.1260e+01,  2.9986e+01, -3.4078e+01, -3.4206e+01,\n",
       "          -2.9983e+01, -1.9229e+00, -2.3805e+01, -4.1792e+01,  1.1930e+01,\n",
       "           4.8399e+01,  3.3250e+01, -4.2737e+00,  4.9744e+00,  3.9431e+01,\n",
       "          -4.1528e+00,  1.6820e+01, -1.4018e+01, -1.0960e+01, -2.9564e-02,\n",
       "           1.3582e+00, -4.9702e+00,  2.7639e+01, -5.3414e+00,  1.3938e+01,\n",
       "          -2.3290e+01,  2.3750e+01, -2.3914e+00,  3.8436e+01,  2.8766e+01,\n",
       "          -2.0846e+01, -5.7296e+01, -5.2645e+00,  1.2146e+01,  2.6889e+01,\n",
       "           2.8688e+01, -1.4725e+01, -2.9688e+01, -1.5421e+01, -3.0242e+00,\n",
       "           1.6587e+01, -1.6913e+01,  1.6130e+00,  2.1838e+01, -1.1585e+01,\n",
       "           3.6109e+01,  2.0169e+00, -1.3832e+01,  1.5335e+01,  1.6484e+01,\n",
       "           4.8017e+00,  3.1784e+01, -1.6013e+01,  2.2935e+01,  1.1252e+01,\n",
       "           6.0381e+01, -3.5040e+01, -1.0996e+01,  4.8666e+01,  7.4903e+00,\n",
       "          -2.3075e+00,  3.3447e+01, -2.8660e+01, -5.5757e+00, -1.7676e+01,\n",
       "           8.6053e+00, -2.5341e+00,  1.2779e+01, -1.0508e+01,  3.5577e+01,\n",
       "           8.8740e+00,  9.4976e+00,  5.0077e+01, -7.8007e+00, -3.7346e+00,\n",
       "           1.6449e+01, -5.6368e+01, -1.4368e-01, -1.9163e+01,  1.3083e+01,\n",
       "           2.6258e+01,  2.1851e+01, -4.0708e+01, -1.4058e+01, -3.9088e+01,\n",
       "          -3.5892e+01, -1.8303e+01,  4.5842e+00,  1.3531e+01,  5.2744e+00,\n",
       "          -1.3669e+01,  1.8191e+01, -2.5821e+01, -2.6923e+01,  1.2661e+01,\n",
       "           3.3575e+01,  1.6445e+01, -5.7001e+01, -1.5663e+01,  5.9084e+00,\n",
       "          -6.4403e-01,  1.2930e+01,  1.9848e+01, -2.5704e+00,  1.2301e+01,\n",
       "           4.8158e+01, -4.1326e+01,  9.8319e+00, -4.5715e+01, -1.1830e+01,\n",
       "           6.3745e-01,  3.1811e+01, -2.1008e+01,  4.7415e+01,  1.1371e+00,\n",
       "           2.1877e+01, -5.5504e+01, -9.3164e+00]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.forward(x,x,x,mask=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3704, 0.3704, 0.3704],\n",
       "        [0.0000, 0.3704, 0.3704],\n",
       "        [0.0000, 0.3704, 0.3704]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.attention_scores[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16*32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 128])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.transpose(0,1).is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  0.,   1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.,\n",
       "           11.,  12.,  13.,  14.,  15.,  16.,  17.,  18.,  19.,  20.,  21.,\n",
       "           22.,  23.,  24.,  25.,  26.,  27.,  28.,  29.,  30.,  31.,  32.,\n",
       "           33.,  34.,  35.,  36.,  37.,  38.,  39.,  40.,  41.,  42.,  43.,\n",
       "           44.,  45.,  46.,  47.,  48.,  49.,  50.,  51.,  52.,  53.,  54.,\n",
       "           55.,  56.,  57.,  58.,  59.,  60.,  61.,  62.,  63.,  64.,  65.,\n",
       "           66.,  67.,  68.,  69.,  70.,  71.,  72.,  73.,  74.,  75.,  76.,\n",
       "           77.,  78.,  79.,  80.,  81.,  82.,  83.,  84.,  85.,  86.,  87.,\n",
       "           88.,  89.,  90.,  91.,  92.,  93.,  94.,  95.,  96.,  97.,  98.,\n",
       "           99., 100., 101., 102., 103., 104., 105., 106., 107., 108., 109.,\n",
       "          110., 111., 112., 113., 114., 115., 116., 117., 118., 119., 120.,\n",
       "          121., 122., 123., 124., 125., 126., 127.],\n",
       "         [  0.,   1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.,\n",
       "           11.,  12.,  13.,  14.,  15.,  16.,  17.,  18.,  19.,  20.,  21.,\n",
       "           22.,  23.,  24.,  25.,  26.,  27.,  28.,  29.,  30.,  31.,  32.,\n",
       "           33.,  34.,  35.,  36.,  37.,  38.,  39.,  40.,  41.,  42.,  43.,\n",
       "           44.,  45.,  46.,  47.,  48.,  49.,  50.,  51.,  52.,  53.,  54.,\n",
       "           55.,  56.,  57.,  58.,  59.,  60.,  61.,  62.,  63.,  64.,  65.,\n",
       "           66.,  67.,  68.,  69.,  70.,  71.,  72.,  73.,  74.,  75.,  76.,\n",
       "           77.,  78.,  79.,  80.,  81.,  82.,  83.,  84.,  85.,  86.,  87.,\n",
       "           88.,  89.,  90.,  91.,  92.,  93.,  94.,  95.,  96.,  97.,  98.,\n",
       "           99., 100., 101., 102., 103., 104., 105., 106., 107., 108., 109.,\n",
       "          110., 111., 112., 113., 114., 115., 116., 117., 118., 119., 120.,\n",
       "          121., 122., 123., 124., 125., 126., 127.],\n",
       "         [  0.,   1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.,\n",
       "           11.,  12.,  13.,  14.,  15.,  16.,  17.,  18.,  19.,  20.,  21.,\n",
       "           22.,  23.,  24.,  25.,  26.,  27.,  28.,  29.,  30.,  31.,  32.,\n",
       "           33.,  34.,  35.,  36.,  37.,  38.,  39.,  40.,  41.,  42.,  43.,\n",
       "           44.,  45.,  46.,  47.,  48.,  49.,  50.,  51.,  52.,  53.,  54.,\n",
       "           55.,  56.,  57.,  58.,  59.,  60.,  61.,  62.,  63.,  64.,  65.,\n",
       "           66.,  67.,  68.,  69.,  70.,  71.,  72.,  73.,  74.,  75.,  76.,\n",
       "           77.,  78.,  79.,  80.,  81.,  82.,  83.,  84.,  85.,  86.,  87.,\n",
       "           88.,  89.,  90.,  91.,  92.,  93.,  94.,  95.,  96.,  97.,  98.,\n",
       "           99., 100., 101., 102., 103., 104., 105., 106., 107., 108., 109.,\n",
       "          110., 111., 112., 113., 114., 115., 116., 117., 118., 119., 120.,\n",
       "          121., 122., 123., 124., 125., 126., 127.]]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.transpose(0,1).contiguous().view(1,3,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardBlock(nn.Module):\n",
    "    def __init__(self, d_model: int, d_ff: int, dropout: float ) -> None:\n",
    "        super().__init__()\n",
    "        self.linear_1 = nn.Linear(d_model, d_ff)  # W1 and B1 \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear_2=nn.Linear(d_ff, d_model) # W2 and B2 \n",
    "\n",
    "    def forward(self,x):\n",
    "        # (Batch, Seq_Leln, d_model) --> (Batch, Seq_Len, d_ff) ---> (Batch, Seq_Len, d_model)\n",
    "        x = self.linear_1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear_2(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=FeedForwardBlock(128,256,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 128])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.forward(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A: \n",
    "    def __init__(self,a,b):\n",
    "        self.a=a\n",
    "        self.b=b\n",
    "        self.ds=[1,2,3,4,5,5,34,3,4,6]\n",
    "    def su_(self,c):\n",
    "        return self.a+self.b+self.c\n",
    "    def __len__(self):\n",
    "        return len(self.ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'A' object has no attribute 'len'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[89], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m A(\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m)\u001b[38;5;241m.\u001b[39mlen()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'A' object has no attribute 'len'"
     ]
    }
   ],
   "source": [
    "A(3,4).len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(A(3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'new_sum']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterator(a):\n",
    "    for i in range(a):\n",
    "        yield i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "for i in iterator(10):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def causal_mask(size):\n",
    "    mask = torch.triu(torch.ones(1,size,size), diagonal=1).type(torch.int)\n",
    "\n",
    "    return mask == 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ True, False, False, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False],\n",
       "         [ True,  True, False, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False],\n",
       "         [ True,  True,  True, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False],\n",
       "         [ True,  True,  True,  True, False, False, False, False, False, False,\n",
       "          False, False, False, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True, False, False, False, False, False,\n",
       "          False, False, False, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True, False, False, False, False,\n",
       "          False, False, False, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
       "          False, False, False, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "          False, False, False, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "          False, False, False, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          False, False, False, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True, False, False, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True, False, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True, False, False, False, False, False, False,\n",
       "          False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True, False, False, False, False, False,\n",
       "          False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True, False, False, False, False,\n",
       "          False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
       "          False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "          False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "          False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True]]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "causal_mask(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=4\n",
    "mask = torch.triu(torch.ones(1,size,size), diagonal=1).type(torch.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 1, 1, 1],\n",
       "         [0, 0, 1, 1],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 0, 0, 0]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class BilingualDataset(Dataset):\n",
    "\n",
    "    def __init__(self, ds, tokenizer_src, tokenizer_tgt,src_lang, tgt_lang, seq_len) -> None:\n",
    "        super().__init__()\n",
    "        self.ds = ds\n",
    "        self.tokenizer_src = tokenizer_src\n",
    "        self.tokenizer_tgt = tokenizer_tgt \n",
    "        self.src_lang = src_lang \n",
    "        self.tgt_lang = src_lang \n",
    "\n",
    "        self.sos_token = torch.Tensor([tokenizer_src.token_to_id(['[SOS]'])], dtype=torch.int64)\n",
    "        self.eos_token = torch.Tensor([tokenizer_src.token_to_id(['[EOS]'])], dtype=torch.int64)\n",
    "        self.pad_token = torch.Tensor([tokenizer_src.token_to_id(['[PAD]'])], dtype=torch.int64)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        src_target_pair = self.ds[index]\n",
    "        src_text = src_target_pair['translation'][self.src_lang]\n",
    "        tgt_text = src_target_pair['translation'][self.tgt_lang]\n",
    "\n",
    "        enc_input_tokens = self.tokenizer_src.encode(src_text).ids\n",
    "        dec_input_tokens = self.tokenizer_tgt.encode(tgt_text).ids\n",
    "\n",
    "        enc_num_padding_tokens = self.seq_len - len(enc_input_tokens) - 2\n",
    "        dec_num_padding_tokens = self.seq_len - len(dec_input_tokens) - 1\n",
    "\n",
    "        if enc_num_padding_tokens < 0 or dec_num_padding_tokens <0: \n",
    "            raise ValueError('sentence is too long') \n",
    "        \n",
    "        # Add SOS and EOS to the source text\n",
    "        encoder_input = torch.cat(\n",
    "            [self.sos_token,\n",
    "             torch.tensor(enc_input_tokens, dtype=torch.int64),\n",
    "             self.eos_token,\n",
    "             torch.tensor([self.pad_token] * enc_num_padding_tokens, dtype=torch.int64)\n",
    "             ]\n",
    "        )\n",
    "        # Add SOS to the decoder input\n",
    "        decoder_input = torch.cat(\n",
    "            [ \n",
    "                self.sos_token, \n",
    "                torch.tensor(dec_input_tokens, dtype=torch.int64),\n",
    "                torch.tensor([self.pad_token] * dec_num_padding_tokens, dtype=torch.int64)\n",
    "\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Add EOS to the label (What we expect as output from the decoder)\n",
    "\n",
    "        label = torch.cat(\n",
    "\n",
    "            [\n",
    "                torch.tensor(dec_input_tokens, dtype=torch.int64),\n",
    "                self.eos_token,\n",
    "                torch.tensor([self.pad_token] * dec_num_padding_tokens, dtype=torch.int64)\n",
    "\n",
    "\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        assert encoder_input.size(0) == self.seq_len\n",
    "        assert decoder_input.size(0) == self.seq_len\n",
    "        assert label.size(0) == self.seq_len\n",
    "\n",
    "        return {\n",
    "            \"encoder_input\":encoder_input, # (Seq_Len)\n",
    "            \"decoder_input\":decoder_input , # (Seq_Len)\n",
    "            \"encoder_mask\":(encoder_input != self.pad_token).unsqueeze(0).unsqueeze(0).int(), # (1,1, Seq_Len)\n",
    "            \"decoder_mask\":(decoder_input != self.pad_token).unseueeze(0).unseueeze(0).int() & causal_mask(decoder_input.size(0))  # (1, Seq_Len)  &  (1,Seq_Len, Seq_Len)\n",
    "\n",
    "        } \n",
    "\n",
    "def causal_mask(size):\n",
    "    mask = torch.triu(torch.ones(1,size,size), diagonal=1).type(torch.int)\n",
    "\n",
    "    return mask == 0 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "from datasets import load_dataset\n",
    "from tokenizers import Tokenizer \n",
    "from tokenizers.models import WordLevel \n",
    "from tokenizers.trainers import WordLevelTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace \n",
    "from dataset import causal_mask\n",
    "from model import build_transformer\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from pathlib import Path\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "from config import get_config, get_weights_file_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config():\n",
    "    return {\n",
    "        \"batch_size\":8, \n",
    "        \"num_epochs\":20,\n",
    "        \"lr\":10**-4, \n",
    "        \"seq_len\":350, \n",
    "        \"d_model\":512,\n",
    "        \"lang_src\": \"en\",\n",
    "        \"lang_tgt\":\"it\",\n",
    "        \"model_folder\":\"weights\",\n",
    "        \"model_filename\":\"tmodel_\",\n",
    "        \"preload\":None,\n",
    "        \"tokenizer_file\":\"tokenizer_{0}.json\",\n",
    "        \"experiment_name\": \"runs/tmodel\"\n",
    "\n",
    "    }\n",
    "\n",
    "def get_weights_file_path(config,epoch: str):\n",
    "    model_folder = config['model_folder']\n",
    "    model_basename = config['model_basename']\n",
    "    model_filename = f\"{model_basename}{epoch}.pt\"\n",
    "    return str(path('.') / model_folder / model_filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardBlock(nn.Module):\n",
    "    def __init__(self, d_model: int, d_ff: int, dropout: float ) -> None:\n",
    "        super().__init__()\n",
    "        self.linear_1 = nn.Linear(d_model, d_ff)  # W1 and B1 \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear_2 = nn.Linear(d_ff, d_model) # W2 and B2 \n",
    "\n",
    "    def forward(self,x):\n",
    "        # (Batch, Seq_Leln, d_model) --> (Batch, Seq_Len, d_ff) ---> (Batch, Seq_Len, d_model)\n",
    "        #x = self.linear_1(x)\n",
    "        #x = torch.relu(x)\n",
    "        #x = self.dropout(x)\n",
    "        #x = self.linear_2(x)\n",
    "        return self.linear_2(self.dropout(torch.relu(self.linear_1(x)))) \n",
    "class ResidualConnection(nn.Module):\n",
    "    \n",
    "    def __init__(self, dropout:float) -> None:\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.norm = LayerNormalization()\n",
    "    \n",
    "    def forward(self, x, sublayer):\n",
    "        return x + self.dropout(sublayer(self.norm(x)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FeedForwardBlock(64, 2048, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [[[i for i in range(0,64)],[i for i in range(0,64)],[i for i in range(0,64)]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.tensor(x).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"hindi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1=open(\"data/train.en\")\n",
    "f2=open(\"data/train.hi\")\n",
    "hindi=[]\n",
    "english=[]\n",
    "count=0\n",
    "\n",
    "for eng in f1.readlines():\n",
    "    #eng=eng.strip()\n",
    "    english.append(eng)\n",
    "    if count>50000:\n",
    "        break\n",
    "    count=count+1\n",
    "count=0\n",
    "for hin in f2.readlines():\n",
    "    #hin=hin.strip()\n",
    "    hindi.append(hin)\n",
    "    if count>50000:\n",
    "        break\n",
    "    count=count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/train.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>hindi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>However, Paes, who was partnering Australia's Paul Hanley, could only go as far as the quarterfinals where they lost to Bhupathi and Knowles</td>\n",
       "      <td>आस्ट्रेलिया के पाल हेनली के साथ जोड़ी बनाने वाले पेस मियामी में क्वार्टरफाइनल तक ही पहुंच सके क्योंकि इस दौर में उन्हें भूपति और नोल्स ने हराया था।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Whosoever desires the reward of the world, with Allah is the reward of the world and of the Everlasting Life. Allah is the Hearer, the Seer.</td>\n",
       "      <td>और जो शख्स (अपने आमाल का) बदला दुनिया ही में चाहता है तो ख़ुदा के पास दुनिया व आख़िरत दोनों का अज्र मौजूद है और ख़ुदा तो हर शख्स की सुनता और सबको देखता है</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The value of insects in the biosphere is enormous because they outnumber all other living groups in measure of species richness.</td>\n",
       "      <td>जैव-मंडल में कीड़ों का मूल्य बहुत है, क्योंकि प्रजातियों की समृद्धि के मामले में उनकी संख्या अन्य जीव समूहों से ज़्यादा है।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mithali To Anchor Indian Team Against Australia in ODIs</td>\n",
       "      <td>आस्ट्रेलिया के खिलाफ वनडे टीम की कमान मिताली को</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>After the assent of the Honble President on 8thSeptember, 2016, the 101thConstitutional Amendment Act, 2016 came into existence</td>\n",
       "      <td>8 सितम्‍बर, 2016 को माननीय राष्‍ट्रपति की स्‍वीकृति मिलने के बाद 101वां संविधान संशोधन अधिनियम, 2016 अस्तित्‍व में आया</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The court has fixed a hearing for February 12</td>\n",
       "      <td>अदालत ने इस मामले में आगे की सुनवाई के लिए एक फरवरी की तारीख़ तय की</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Please select the position where the track should be split.</td>\n",
       "      <td>जहाँ पर ट्रैक को विभाजित किया जाना है, कृपया वह स्थान चुनें.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>As per police, armys 22RR, special operation Group (SOG) of police and the Central Reserve Police Force (CRPF) cordoned the village and launched search operation in the area.</td>\n",
       "      <td>इसके तुरंत बाद सेना की 22 राष्ट्रीय राइफल्स (आरआर), सीआरपीएफ और पुलिस के स्पेशल ऑपरेशन ग्रुप (एसओजी) के जवानों द्वारा इलाके की घेराबंदी कर तलाशी अभियान चलाया।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Jharkhand chief minister Hemant Soren</td>\n",
       "      <td>झारखंड के मुख्यमंत्री हेमंत सोरेन (फोटोः पीटीआई)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Arvind Kumar, SHO of the sector 55/56 police station, said a case has been registered under section 376-D (gang rape) of the Indian Penal Code.</td>\n",
       "      <td>सेक्टर 55/56 के एसएचओ अरविंद कुमार ने बताया कि इस मामले में आईपीसी की धारा 376-डी (गैंगरेप) के तहत मामला दर्ज कर लिया गया है।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Briefing media in New Delhi today, party's State-in-charge, Anil Jain said, after the meeting the party will meet the Governor to stake claim for government formation in the state.</td>\n",
       "      <td>आज नई दिल्ली में मीडिया से बातचीत में पार्टी के राज्य प्रभारी अनिल जैन ने बताया कि बैठक के बाद पार्टी, सरकार के गठन का दावा पेश करने के लिए राज्यपाल से मिलेगी।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>\"Jesus responded, as he taught in the temple, \"\"How is it that the scribes say that the Christ is the son of David?\"</td>\n",
       "      <td>फिर यीशु ने मन्दिर में उपदेश करते हुए यह कहा, कि शास्त्री क्योंकर कहते हैं, कि मसीह दाऊद का पुत्रा है?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Senior leaders of all major parties held electioneering in favour of their candidates.</td>\n",
       "      <td>सभी मुख्य पार्टियों के वरिष्ठ नेताओं ने अपने-अपने उम्मीदवारों के पक्ष में चुनाव प्रचार किया।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Meanwhile, three people came there on a bike.</td>\n",
       "      <td>इसी बीच एक बाइक पर तीन लोग आते दिखाई दिए।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Katrina shared the video on Instagram.</td>\n",
       "      <td>कटरीना ने ये वीड‍ियो अपनी इंस्‍टास्‍टोरी में शेयर क‍िया है.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>He does this because he is angry at the alleged desecration of the Indian flag</td>\n",
       "      <td>वह ऐसा इसलिए करता है, क्योंकि वह भारतीय तिरंगे के कथित अनादर से क्रोधित है</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Attempts to contact Randhawa on his mobile over the past one week have remained futile.</td>\n",
       "      <td>रंधावा से एक हफ्ते से उनके मोबाईल पर सम्पर्क करने की कोशिश की गयी, लेकिन बात नहीं हो पायी।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>The Alto 800 incorporates a Wavefront Design, a more traditional car look, compared to the Nano</td>\n",
       "      <td>नैनो की तुलना में अल्टो 800 का डिज़ाइन वेवफ्रंट है जो पारंपरिक कार की तरह दिखता है।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Share videos</td>\n",
       "      <td>वीडियो क्लिप शेयर किए</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>\"\"\"Wunderlich and his wife, Petra, are both gardeners, who themselves graduated from a normal high school, which they attended \"\"\"\"not reluctantly,\"\"\"\" Dirk said.\"\"\"</td>\n",
       "      <td>डिर्क और उनकी पत्नी पेट्रा दोनों बागवानी करते हैं और वे दोनों खुद एक सामान्य हाई स्कूल से पढ़े थे.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                 english  \\\n",
       "0                                           However, Paes, who was partnering Australia's Paul Hanley, could only go as far as the quarterfinals where they lost to Bhupathi and Knowles   \n",
       "1                                           Whosoever desires the reward of the world, with Allah is the reward of the world and of the Everlasting Life. Allah is the Hearer, the Seer.   \n",
       "2                                                       The value of insects in the biosphere is enormous because they outnumber all other living groups in measure of species richness.   \n",
       "3                                                                                                                                Mithali To Anchor Indian Team Against Australia in ODIs   \n",
       "4                                                        After the assent of the Honble President on 8thSeptember, 2016, the 101thConstitutional Amendment Act, 2016 came into existence   \n",
       "5                                                                                                                                          The court has fixed a hearing for February 12   \n",
       "6                                                                                                                            Please select the position where the track should be split.   \n",
       "7         As per police, armys 22RR, special operation Group (SOG) of police and the Central Reserve Police Force (CRPF) cordoned the village and launched search operation in the area.   \n",
       "8                                                                                                                                                  Jharkhand chief minister Hemant Soren   \n",
       "9                                        Arvind Kumar, SHO of the sector 55/56 police station, said a case has been registered under section 376-D (gang rape) of the Indian Penal Code.   \n",
       "10  Briefing media in New Delhi today, party's State-in-charge, Anil Jain said, after the meeting the party will meet the Governor to stake claim for government formation in the state.   \n",
       "11                                                                  \"Jesus responded, as he taught in the temple, \"\"How is it that the scribes say that the Christ is the son of David?\"   \n",
       "12                                                                                                Senior leaders of all major parties held electioneering in favour of their candidates.   \n",
       "13                                                                                                                                         Meanwhile, three people came there on a bike.   \n",
       "14                                                                                                                                                Katrina shared the video on Instagram.   \n",
       "15                                                                                                        He does this because he is angry at the alleged desecration of the Indian flag   \n",
       "16                                                                                               Attempts to contact Randhawa on his mobile over the past one week have remained futile.   \n",
       "17                                                                                       The Alto 800 incorporates a Wavefront Design, a more traditional car look, compared to the Nano   \n",
       "18                                                                                                                                                                          Share videos   \n",
       "19                 \"\"\"Wunderlich and his wife, Petra, are both gardeners, who themselves graduated from a normal high school, which they attended \"\"\"\"not reluctantly,\"\"\"\" Dirk said.\"\"\"   \n",
       "\n",
       "                                                                                                                                                              hindi  \n",
       "0                आस्ट्रेलिया के पाल हेनली के साथ जोड़ी बनाने वाले पेस मियामी में क्वार्टरफाइनल तक ही पहुंच सके क्योंकि इस दौर में उन्हें भूपति और नोल्स ने हराया था।  \n",
       "1        और जो शख्स (अपने आमाल का) बदला दुनिया ही में चाहता है तो ख़ुदा के पास दुनिया व आख़िरत दोनों का अज्र मौजूद है और ख़ुदा तो हर शख्स की सुनता और सबको देखता है  \n",
       "2                                       जैव-मंडल में कीड़ों का मूल्य बहुत है, क्योंकि प्रजातियों की समृद्धि के मामले में उनकी संख्या अन्य जीव समूहों से ज़्यादा है।  \n",
       "3                                                                                                                   आस्ट्रेलिया के खिलाफ वनडे टीम की कमान मिताली को  \n",
       "4                                            8 सितम्‍बर, 2016 को माननीय राष्‍ट्रपति की स्‍वीकृति मिलने के बाद 101वां संविधान संशोधन अधिनियम, 2016 अस्तित्‍व में आया  \n",
       "5                                                                                               अदालत ने इस मामले में आगे की सुनवाई के लिए एक फरवरी की तारीख़ तय की  \n",
       "6                                                                                                      जहाँ पर ट्रैक को विभाजित किया जाना है, कृपया वह स्थान चुनें.  \n",
       "7    इसके तुरंत बाद सेना की 22 राष्ट्रीय राइफल्स (आरआर), सीआरपीएफ और पुलिस के स्पेशल ऑपरेशन ग्रुप (एसओजी) के जवानों द्वारा इलाके की घेराबंदी कर तलाशी अभियान चलाया।  \n",
       "8                                                                                                                  झारखंड के मुख्यमंत्री हेमंत सोरेन (फोटोः पीटीआई)  \n",
       "9                                     सेक्टर 55/56 के एसएचओ अरविंद कुमार ने बताया कि इस मामले में आईपीसी की धारा 376-डी (गैंगरेप) के तहत मामला दर्ज कर लिया गया है।  \n",
       "10  आज नई दिल्ली में मीडिया से बातचीत में पार्टी के राज्य प्रभारी अनिल जैन ने बताया कि बैठक के बाद पार्टी, सरकार के गठन का दावा पेश करने के लिए राज्यपाल से मिलेगी।  \n",
       "11                                                           फिर यीशु ने मन्दिर में उपदेश करते हुए यह कहा, कि शास्त्री क्योंकर कहते हैं, कि मसीह दाऊद का पुत्रा है?  \n",
       "12                                                                     सभी मुख्य पार्टियों के वरिष्ठ नेताओं ने अपने-अपने उम्मीदवारों के पक्ष में चुनाव प्रचार किया।  \n",
       "13                                                                                                                        इसी बीच एक बाइक पर तीन लोग आते दिखाई दिए।  \n",
       "14                                                                                                      कटरीना ने ये वीड‍ियो अपनी इंस्‍टास्‍टोरी में शेयर क‍िया है.  \n",
       "15                                                                                       वह ऐसा इसलिए करता है, क्योंकि वह भारतीय तिरंगे के कथित अनादर से क्रोधित है  \n",
       "16                                                                       रंधावा से एक हफ्ते से उनके मोबाईल पर सम्पर्क करने की कोशिश की गयी, लेकिन बात नहीं हो पायी।  \n",
       "17                                                                               नैनो की तुलना में अल्टो 800 का डिज़ाइन वेवफ्रंट है जो पारंपरिक कार की तरह दिखता है।  \n",
       "18                                                                                                                                            वीडियो क्लिप शेयर किए  \n",
       "19                                                               डिर्क और उनकी पत्नी पेट्रा दोनों बागवानी करते हैं और वे दोनों खुद एक सामान्य हाई स्कूल से पढ़े थे.  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x(file):\n",
    "    for i in file.readlines():\n",
    "        yield i.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1=open(\"data/train.en\")\n",
    "f2=open(\"data/train_sample.en\",\"w\")\n",
    "count=0\n",
    "for i in f1.readlines():\n",
    "    count=count+1\n",
    "    f2.write(i)\n",
    "    if count>5000:\n",
    "        break\n",
    "f1.close()\n",
    "f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10125706\n"
     ]
    }
   ],
   "source": [
    "f1=open(\"data/train.hi\")\n",
    "count=0\n",
    "for i in f1.readlines():\n",
    "    count=count+1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tokenizers import Tokenizer \n",
    "from tokenizers.models import WordLevel \n",
    "from tokenizers.trainers import WordLevelTrainer\n",
    "from pathlib import Path\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "\n",
    "\n",
    "def get_all_sentences(ds,lang):\n",
    "    file=open(ds,'r')\n",
    "    for i in file.readlines():\n",
    "        yield i.strip()\n",
    "\n",
    "def get_or_build_tokenizer(ds,lang):\n",
    "    tokenizer_path = Path(\"tokenizer_{}.json\".format(lang))\n",
    "    if not Path.exists(tokenizer_path):\n",
    "        tokenizer =Tokenizer(WordLevel(unk_token='[UNK]'))\n",
    "        tokenizer.pre_tokenizer = Whitespace()\n",
    "        trainer = WordLevelTrainer(special_tokens=[\"[UNK]\",\"[PAD]\",\"[SOS]\",\"[SOS]\",\"[EOS]\"], min_frequency=2)\n",
    "        tokenizer.train_from_iterator(get_all_sentences(ds,lang), trainer=trainer)\n",
    "        tokenizer.save(str(tokenizer_path))\n",
    "    else:\n",
    "        tokenizer = Tokenizer.from_file(str(tokenizer_path))\n",
    "    \n",
    "    return tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tokenizers.Tokenizer at 0x34d359630>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang=\"english\"\n",
    "ds=\"data/train_sample.en\"\n",
    "get_or_build_tokenizer(ds,lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "\n",
    "tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
    "trainer = BpeTrainer(special_tokens=[\"[UNK]\", \"[PAD]\", \"[SOS]\", \"[EOS]\"],min_frequency=2,vocab_size=10000)\n",
    "tokenizer_path = Path(\"bpe_tokenizer_{}.json\".format(lang))\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "tokenizer.train_from_iterator(get_all_sentences(ds,lang), trainer=trainer)\n",
    "tokenizer.save(str(tokenizer_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tokenizer.encode(\"If the sequence has length n, there are n−1 possible pairs.\").ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'If the sequence has length n , there are n 1 possible pair s .'"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mBpeTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Trainer capable of training a BPE model\n",
       "\n",
       "Args:\n",
       "    vocab_size (:obj:`int`, `optional`):\n",
       "        The size of the final vocabulary, including all tokens and alphabet.\n",
       "\n",
       "    min_frequency (:obj:`int`, `optional`):\n",
       "        The minimum frequency a pair should have in order to be merged.\n",
       "\n",
       "    show_progress (:obj:`bool`, `optional`):\n",
       "        Whether to show progress bars while training.\n",
       "\n",
       "    special_tokens (:obj:`List[Union[str, AddedToken]]`, `optional`):\n",
       "        A list of special tokens the model should know of.\n",
       "\n",
       "    limit_alphabet (:obj:`int`, `optional`):\n",
       "        The maximum different characters to keep in the alphabet.\n",
       "\n",
       "    initial_alphabet (:obj:`List[str]`, `optional`):\n",
       "        A list of characters to include in the initial alphabet, even\n",
       "        if not seen in the training dataset.\n",
       "        If the strings contain more than one character, only the first one\n",
       "        is kept.\n",
       "\n",
       "    continuing_subword_prefix (:obj:`str`, `optional`):\n",
       "        A prefix to be used for every subword that is not a beginning-of-word.\n",
       "\n",
       "    end_of_word_suffix (:obj:`str`, `optional`):\n",
       "        A suffix to be used for every subword that is a end-of-word.\n",
       "\n",
       "    max_token_length (:obj:`int`, `optional`):\n",
       "        Prevents creating tokens longer than the specified size.\n",
       "        This can help with reducing polluting your vocabulary with\n",
       "        highly repetitive tokens like `======` for wikipedia\n",
       "\u001b[0;31mFile:\u001b[0m           ~/anaconda3/envs/deep_learning/lib/python3.12/site-packages/tokenizers/trainers/__init__.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BpeTrainer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import get_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 8,\n",
       " 'num_epochs': 20,\n",
       " 'lr': 0.0001,\n",
       " 'seq_len': 350,\n",
       " 'd_model': 8,\n",
       " 'head': 8,\n",
       " 'encoder': 6,\n",
       " 'decoder': 6,\n",
       " 'datasource': 'data',\n",
       " 'lang_src': 'en',\n",
       " 'lang_tgt': 'hi',\n",
       " 'model_folder': 'weights',\n",
       " 'model_basename': 'tmodel_',\n",
       " 'preload': 'latest',\n",
       " 'tokenizer_file': 'tokenizer_{0}.json',\n",
       " 'experiment_name': 'runs/tmodel'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import bpe_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import get_config as config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 8,\n",
       " 'num_epochs': 20,\n",
       " 'lr': 0.0001,\n",
       " 'seq_len': 350,\n",
       " 'd_model': 8,\n",
       " 'head': 8,\n",
       " 'encoder': 6,\n",
       " 'decoder': 6,\n",
       " 'datasource': 'data',\n",
       " 'lang_src': 'en',\n",
       " 'lang_tgt': 'hi',\n",
       " 'model_folder': 'weights',\n",
       " 'model_basename': 'tmodel_',\n",
       " 'preload': 'latest',\n",
       " 'tokenizer_file': 'tokenizer_{0}.json',\n",
       " 'experiment_name': 'runs/tmodel'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizer import bpe_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m tokenizer_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbpe_tokenizer_en.json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m Tokenizer\u001b[38;5;241m.\u001b[39mfrom_file(\u001b[38;5;28mstr\u001b[39m(tokenizer_path))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer_path=\"bpe_tokenizer_en.json\"\n",
    "tokenizer = Tokenizer.from_file(str(tokenizer_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4448,\n",
       " 3084,\n",
       " 4148,\n",
       " 3091,\n",
       " 5110,\n",
       " 16,\n",
       " 5110,\n",
       " 9335,\n",
       " 7221,\n",
       " 5065,\n",
       " 15,\n",
       " 12137,\n",
       " 16,\n",
       " 9632,\n",
       " 3091,\n",
       " 4899,\n",
       " 9323,\n",
       " 22088,\n",
       " 3148,\n",
       " 10599,\n",
       " 15,\n",
       " 22161,\n",
       " 8343,\n",
       " 3088,\n",
       " 3155,\n",
       " 9199]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizer import bpe_tokenizer   #,get_all_sentences\n",
    "from config import get_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tokenizers.Tokenizer at 0x110e41030>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = get_config() \n",
    "lang=\"en\"\n",
    "data_path =config['datasource'].format(lang)\n",
    "ds = open(data_path,'r')\n",
    "bpe_tokenizer(config, ds, lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (3357829416.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[71], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    Path(config['datasource'].format(\"lang\")\u001b[0m\n\u001b[0m                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "Path(config['datasource'].format(\"lang\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 8,\n",
       " 'num_epochs': 20,\n",
       " 'lr': 0.0001,\n",
       " 'seq_len': 350,\n",
       " 'd_model': 8,\n",
       " 'head': 8,\n",
       " 'encoder': 6,\n",
       " 'decoder': 6,\n",
       " 'datasource': 'data',\n",
       " 'lang_src': 'en',\n",
       " 'lang_tgt': 'hi',\n",
       " 'model_folder': 'weights',\n",
       " 'model_basename': 'tmodel_',\n",
       " 'preload': 'latest',\n",
       " 'tokenizer_file': 'tokenizer_{0}.json',\n",
       " 'experiment_name': 'runs/tmodel'}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lang_src=\"en\"\n",
    "lang_tgt=\"it\"\n",
    "ds_raw = load_dataset(\"opus_books\",f'{\"en\"}-{\"it\"}', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.arrow_dataset.Dataset"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ds_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_TF_DATASET_REFS',\n",
       " '__class__',\n",
       " '__del__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__enter__',\n",
       " '__eq__',\n",
       " '__exit__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getitems__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_build_local_temp_path',\n",
       " '_check_index_is_initialized',\n",
       " '_data',\n",
       " '_estimate_nbytes',\n",
       " '_fingerprint',\n",
       " '_format_columns',\n",
       " '_format_kwargs',\n",
       " '_format_type',\n",
       " '_generate_tables_from_cache_file',\n",
       " '_generate_tables_from_shards',\n",
       " '_get_cache_file_path',\n",
       " '_get_output_signature',\n",
       " '_getitem',\n",
       " '_indexes',\n",
       " '_indices',\n",
       " '_info',\n",
       " '_map_single',\n",
       " '_new_dataset_with_indices',\n",
       " '_output_all_columns',\n",
       " '_push_parquet_shards_to_hub',\n",
       " '_save_to_disk_single',\n",
       " '_select_contiguous',\n",
       " '_select_with_indices_mapping',\n",
       " '_split',\n",
       " 'add_column',\n",
       " 'add_elasticsearch_index',\n",
       " 'add_faiss_index',\n",
       " 'add_faiss_index_from_external_arrays',\n",
       " 'add_item',\n",
       " 'align_labels_with_mapping',\n",
       " 'builder_name',\n",
       " 'cache_files',\n",
       " 'cast',\n",
       " 'cast_column',\n",
       " 'citation',\n",
       " 'class_encode_column',\n",
       " 'cleanup_cache_files',\n",
       " 'column_names',\n",
       " 'config_name',\n",
       " 'data',\n",
       " 'dataset_size',\n",
       " 'description',\n",
       " 'download_checksums',\n",
       " 'download_size',\n",
       " 'drop_index',\n",
       " 'export',\n",
       " 'features',\n",
       " 'filter',\n",
       " 'flatten',\n",
       " 'flatten_indices',\n",
       " 'format',\n",
       " 'formatted_as',\n",
       " 'from_buffer',\n",
       " 'from_csv',\n",
       " 'from_dict',\n",
       " 'from_file',\n",
       " 'from_generator',\n",
       " 'from_json',\n",
       " 'from_list',\n",
       " 'from_pandas',\n",
       " 'from_parquet',\n",
       " 'from_polars',\n",
       " 'from_spark',\n",
       " 'from_sql',\n",
       " 'from_text',\n",
       " 'get_index',\n",
       " 'get_nearest_examples',\n",
       " 'get_nearest_examples_batch',\n",
       " 'homepage',\n",
       " 'info',\n",
       " 'is_index_initialized',\n",
       " 'iter',\n",
       " 'license',\n",
       " 'list_indexes',\n",
       " 'load_elasticsearch_index',\n",
       " 'load_faiss_index',\n",
       " 'load_from_disk',\n",
       " 'map',\n",
       " 'num_columns',\n",
       " 'num_rows',\n",
       " 'prepare_for_task',\n",
       " 'push_to_hub',\n",
       " 'remove_columns',\n",
       " 'rename_column',\n",
       " 'rename_columns',\n",
       " 'reset_format',\n",
       " 'save_faiss_index',\n",
       " 'save_to_disk',\n",
       " 'search',\n",
       " 'search_batch',\n",
       " 'select',\n",
       " 'select_columns',\n",
       " 'set_format',\n",
       " 'set_transform',\n",
       " 'shape',\n",
       " 'shard',\n",
       " 'shuffle',\n",
       " 'size_in_bytes',\n",
       " 'skip',\n",
       " 'sort',\n",
       " 'split',\n",
       " 'supervised_keys',\n",
       " 'take',\n",
       " 'task_templates',\n",
       " 'to_csv',\n",
       " 'to_dict',\n",
       " 'to_iterable_dataset',\n",
       " 'to_json',\n",
       " 'to_list',\n",
       " 'to_pandas',\n",
       " 'to_parquet',\n",
       " 'to_polars',\n",
       " 'to_sql',\n",
       " 'to_tf_dataset',\n",
       " 'train_test_split',\n",
       " 'unique',\n",
       " 'version',\n",
       " 'with_format',\n",
       " 'with_transform']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(ds_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32332, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "from pathlib import PATH\n",
    "\n",
    "class dataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.file = PATH(\"data/train_sample.en\")\n",
    "    def __len__(self):\n",
    "        return len(self.file)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = read_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class dataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.file = pd.read_csv(\"data/train.csv\")\n",
    "    def __len__(self):\n",
    "        return len(self.file)\n",
    "    def __getitem__(self,idx):\n",
    "        src = self.file.iloc[idx]['english']\n",
    "        tgt = self.file.iloc[idx]['hindi']\n",
    "        return src,tgt\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class dataset(Dataset):\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.file = open(\"data/train.en\").readlines()\n",
    "    def __len__(self):\n",
    "        return len(self.file.readlines())\n",
    "    def __getitem__(self,idx):\n",
    "        return self.file.readlines()[idx].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"data/train.en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50001"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(f.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[i for i in range(0,1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b=a[:700],a[700:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 101,\n",
       " 102,\n",
       " 103,\n",
       " 104,\n",
       " 105,\n",
       " 106,\n",
       " 107,\n",
       " 108,\n",
       " 109,\n",
       " 110,\n",
       " 111,\n",
       " 112,\n",
       " 113,\n",
       " 114,\n",
       " 115,\n",
       " 116,\n",
       " 117,\n",
       " 118,\n",
       " 119,\n",
       " 120,\n",
       " 121,\n",
       " 122,\n",
       " 123,\n",
       " 124,\n",
       " 125,\n",
       " 126,\n",
       " 127,\n",
       " 128,\n",
       " 129,\n",
       " 130,\n",
       " 131,\n",
       " 132,\n",
       " 133,\n",
       " 134,\n",
       " 135,\n",
       " 136,\n",
       " 137,\n",
       " 138,\n",
       " 139,\n",
       " 140,\n",
       " 141,\n",
       " 142,\n",
       " 143,\n",
       " 144,\n",
       " 145,\n",
       " 146,\n",
       " 147,\n",
       " 148,\n",
       " 149,\n",
       " 150,\n",
       " 151,\n",
       " 152,\n",
       " 153,\n",
       " 154,\n",
       " 155,\n",
       " 156,\n",
       " 157,\n",
       " 158,\n",
       " 159,\n",
       " 160,\n",
       " 161,\n",
       " 162,\n",
       " 163,\n",
       " 164,\n",
       " 165,\n",
       " 166,\n",
       " 167,\n",
       " 168,\n",
       " 169,\n",
       " 170,\n",
       " 171,\n",
       " 172,\n",
       " 173,\n",
       " 174,\n",
       " 175,\n",
       " 176,\n",
       " 177,\n",
       " 178,\n",
       " 179,\n",
       " 180,\n",
       " 181,\n",
       " 182,\n",
       " 183,\n",
       " 184,\n",
       " 185,\n",
       " 186,\n",
       " 187,\n",
       " 188,\n",
       " 189,\n",
       " 190,\n",
       " 191,\n",
       " 192,\n",
       " 193,\n",
       " 194,\n",
       " 195,\n",
       " 196,\n",
       " 197,\n",
       " 198,\n",
       " 199,\n",
       " 200,\n",
       " 201,\n",
       " 202,\n",
       " 203,\n",
       " 204,\n",
       " 205,\n",
       " 206,\n",
       " 207,\n",
       " 208,\n",
       " 209,\n",
       " 210,\n",
       " 211,\n",
       " 212,\n",
       " 213,\n",
       " 214,\n",
       " 215,\n",
       " 216,\n",
       " 217,\n",
       " 218,\n",
       " 219,\n",
       " 220,\n",
       " 221,\n",
       " 222,\n",
       " 223,\n",
       " 224,\n",
       " 225,\n",
       " 226,\n",
       " 227,\n",
       " 228,\n",
       " 229,\n",
       " 230,\n",
       " 231,\n",
       " 232,\n",
       " 233,\n",
       " 234,\n",
       " 235,\n",
       " 236,\n",
       " 237,\n",
       " 238,\n",
       " 239,\n",
       " 240,\n",
       " 241,\n",
       " 242,\n",
       " 243,\n",
       " 244,\n",
       " 245,\n",
       " 246,\n",
       " 247,\n",
       " 248,\n",
       " 249,\n",
       " 250,\n",
       " 251,\n",
       " 252,\n",
       " 253,\n",
       " 254,\n",
       " 255,\n",
       " 256,\n",
       " 257,\n",
       " 258,\n",
       " 259,\n",
       " 260,\n",
       " 261,\n",
       " 262,\n",
       " 263,\n",
       " 264,\n",
       " 265,\n",
       " 266,\n",
       " 267,\n",
       " 268,\n",
       " 269,\n",
       " 270,\n",
       " 271,\n",
       " 272,\n",
       " 273,\n",
       " 274,\n",
       " 275,\n",
       " 276,\n",
       " 277,\n",
       " 278,\n",
       " 279,\n",
       " 280,\n",
       " 281,\n",
       " 282,\n",
       " 283,\n",
       " 284,\n",
       " 285,\n",
       " 286,\n",
       " 287,\n",
       " 288,\n",
       " 289,\n",
       " 290,\n",
       " 291,\n",
       " 292,\n",
       " 293,\n",
       " 294,\n",
       " 295,\n",
       " 296,\n",
       " 297,\n",
       " 298,\n",
       " 299,\n",
       " 300,\n",
       " 301,\n",
       " 302,\n",
       " 303,\n",
       " 304,\n",
       " 305,\n",
       " 306,\n",
       " 307,\n",
       " 308,\n",
       " 309,\n",
       " 310,\n",
       " 311,\n",
       " 312,\n",
       " 313,\n",
       " 314,\n",
       " 315,\n",
       " 316,\n",
       " 317,\n",
       " 318,\n",
       " 319,\n",
       " 320,\n",
       " 321,\n",
       " 322,\n",
       " 323,\n",
       " 324,\n",
       " 325,\n",
       " 326,\n",
       " 327,\n",
       " 328,\n",
       " 329,\n",
       " 330,\n",
       " 331,\n",
       " 332,\n",
       " 333,\n",
       " 334,\n",
       " 335,\n",
       " 336,\n",
       " 337,\n",
       " 338,\n",
       " 339,\n",
       " 340,\n",
       " 341,\n",
       " 342,\n",
       " 343,\n",
       " 344,\n",
       " 345,\n",
       " 346,\n",
       " 347,\n",
       " 348,\n",
       " 349,\n",
       " 350,\n",
       " 351,\n",
       " 352,\n",
       " 353,\n",
       " 354,\n",
       " 355,\n",
       " 356,\n",
       " 357,\n",
       " 358,\n",
       " 359,\n",
       " 360,\n",
       " 361,\n",
       " 362,\n",
       " 363,\n",
       " 364,\n",
       " 365,\n",
       " 366,\n",
       " 367,\n",
       " 368,\n",
       " 369,\n",
       " 370,\n",
       " 371,\n",
       " 372,\n",
       " 373,\n",
       " 374,\n",
       " 375,\n",
       " 376,\n",
       " 377,\n",
       " 378,\n",
       " 379,\n",
       " 380,\n",
       " 381,\n",
       " 382,\n",
       " 383,\n",
       " 384,\n",
       " 385,\n",
       " 386,\n",
       " 387,\n",
       " 388,\n",
       " 389,\n",
       " 390,\n",
       " 391,\n",
       " 392,\n",
       " 393,\n",
       " 394,\n",
       " 395,\n",
       " 396,\n",
       " 397,\n",
       " 398,\n",
       " 399,\n",
       " 400,\n",
       " 401,\n",
       " 402,\n",
       " 403,\n",
       " 404,\n",
       " 405,\n",
       " 406,\n",
       " 407,\n",
       " 408,\n",
       " 409,\n",
       " 410,\n",
       " 411,\n",
       " 412,\n",
       " 413,\n",
       " 414,\n",
       " 415,\n",
       " 416,\n",
       " 417,\n",
       " 418,\n",
       " 419,\n",
       " 420,\n",
       " 421,\n",
       " 422,\n",
       " 423,\n",
       " 424,\n",
       " 425,\n",
       " 426,\n",
       " 427,\n",
       " 428,\n",
       " 429,\n",
       " 430,\n",
       " 431,\n",
       " 432,\n",
       " 433,\n",
       " 434,\n",
       " 435,\n",
       " 436,\n",
       " 437,\n",
       " 438,\n",
       " 439,\n",
       " 440,\n",
       " 441,\n",
       " 442,\n",
       " 443,\n",
       " 444,\n",
       " 445,\n",
       " 446,\n",
       " 447,\n",
       " 448,\n",
       " 449,\n",
       " 450,\n",
       " 451,\n",
       " 452,\n",
       " 453,\n",
       " 454,\n",
       " 455,\n",
       " 456,\n",
       " 457,\n",
       " 458,\n",
       " 459,\n",
       " 460,\n",
       " 461,\n",
       " 462,\n",
       " 463,\n",
       " 464,\n",
       " 465,\n",
       " 466,\n",
       " 467,\n",
       " 468,\n",
       " 469,\n",
       " 470,\n",
       " 471,\n",
       " 472,\n",
       " 473,\n",
       " 474,\n",
       " 475,\n",
       " 476,\n",
       " 477,\n",
       " 478,\n",
       " 479,\n",
       " 480,\n",
       " 481,\n",
       " 482,\n",
       " 483,\n",
       " 484,\n",
       " 485,\n",
       " 486,\n",
       " 487,\n",
       " 488,\n",
       " 489,\n",
       " 490,\n",
       " 491,\n",
       " 492,\n",
       " 493,\n",
       " 494,\n",
       " 495,\n",
       " 496,\n",
       " 497,\n",
       " 498,\n",
       " 499,\n",
       " 500,\n",
       " 501,\n",
       " 502,\n",
       " 503,\n",
       " 504,\n",
       " 505,\n",
       " 506,\n",
       " 507,\n",
       " 508,\n",
       " 509,\n",
       " 510,\n",
       " 511,\n",
       " 512,\n",
       " 513,\n",
       " 514,\n",
       " 515,\n",
       " 516,\n",
       " 517,\n",
       " 518,\n",
       " 519,\n",
       " 520,\n",
       " 521,\n",
       " 522,\n",
       " 523,\n",
       " 524,\n",
       " 525,\n",
       " 526,\n",
       " 527,\n",
       " 528,\n",
       " 529,\n",
       " 530,\n",
       " 531,\n",
       " 532,\n",
       " 533,\n",
       " 534,\n",
       " 535,\n",
       " 536,\n",
       " 537,\n",
       " 538,\n",
       " 539,\n",
       " 540,\n",
       " 541,\n",
       " 542,\n",
       " 543,\n",
       " 544,\n",
       " 545,\n",
       " 546,\n",
       " 547,\n",
       " 548,\n",
       " 549,\n",
       " 550,\n",
       " 551,\n",
       " 552,\n",
       " 553,\n",
       " 554,\n",
       " 555,\n",
       " 556,\n",
       " 557,\n",
       " 558,\n",
       " 559,\n",
       " 560,\n",
       " 561,\n",
       " 562,\n",
       " 563,\n",
       " 564,\n",
       " 565,\n",
       " 566,\n",
       " 567,\n",
       " 568,\n",
       " 569,\n",
       " 570,\n",
       " 571,\n",
       " 572,\n",
       " 573,\n",
       " 574,\n",
       " 575,\n",
       " 576,\n",
       " 577,\n",
       " 578,\n",
       " 579,\n",
       " 580,\n",
       " 581,\n",
       " 582,\n",
       " 583,\n",
       " 584,\n",
       " 585,\n",
       " 586,\n",
       " 587,\n",
       " 588,\n",
       " 589,\n",
       " 590,\n",
       " 591,\n",
       " 592,\n",
       " 593,\n",
       " 594,\n",
       " 595,\n",
       " 596,\n",
       " 597,\n",
       " 598,\n",
       " 599,\n",
       " 600,\n",
       " 601,\n",
       " 602,\n",
       " 603,\n",
       " 604,\n",
       " 605,\n",
       " 606,\n",
       " 607,\n",
       " 608,\n",
       " 609,\n",
       " 610,\n",
       " 611,\n",
       " 612,\n",
       " 613,\n",
       " 614,\n",
       " 615,\n",
       " 616,\n",
       " 617,\n",
       " 618,\n",
       " 619,\n",
       " 620,\n",
       " 621,\n",
       " 622,\n",
       " 623,\n",
       " 624,\n",
       " 625,\n",
       " 626,\n",
       " 627,\n",
       " 628,\n",
       " 629,\n",
       " 630,\n",
       " 631,\n",
       " 632,\n",
       " 633,\n",
       " 634,\n",
       " 635,\n",
       " 636,\n",
       " 637,\n",
       " 638,\n",
       " 639,\n",
       " 640,\n",
       " 641,\n",
       " 642,\n",
       " 643,\n",
       " 644,\n",
       " 645,\n",
       " 646,\n",
       " 647,\n",
       " 648,\n",
       " 649,\n",
       " 650,\n",
       " 651,\n",
       " 652,\n",
       " 653,\n",
       " 654,\n",
       " 655,\n",
       " 656,\n",
       " 657,\n",
       " 658,\n",
       " 659,\n",
       " 660,\n",
       " 661,\n",
       " 662,\n",
       " 663,\n",
       " 664,\n",
       " 665,\n",
       " 666,\n",
       " 667,\n",
       " 668,\n",
       " 669,\n",
       " 670,\n",
       " 671,\n",
       " 672,\n",
       " 673,\n",
       " 674,\n",
       " 675,\n",
       " 676,\n",
       " 677,\n",
       " 678,\n",
       " 679,\n",
       " 680,\n",
       " 681,\n",
       " 682,\n",
       " 683,\n",
       " 684,\n",
       " 685,\n",
       " 686,\n",
       " 687,\n",
       " 688,\n",
       " 689,\n",
       " 690,\n",
       " 691,\n",
       " 692,\n",
       " 693,\n",
       " 694,\n",
       " 695,\n",
       " 696,\n",
       " 697,\n",
       " 698,\n",
       " 699]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# URL of the file\n",
    "url = \"https://drive.google.com/uc?export=download&id=1Tit_Fz9pfQhQxlSGGOkGRgw59TuVtpF7\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Open a local file with write-binary mode\n",
    "    with open(\"data/sample_new.en\", \"wb\") as file:\n",
    "        # Write the content of the response (the file) to the local file\n",
    "        file.write(response.content)\n",
    "    print(\"File downloaded successfully.\")\n",
    "else:\n",
    "    print(\"Failed to download the file. Status code:\", response.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=pd.read_csv(\"https://drive.google.com/uc?export=download&id=1Tit_Fz9pfQhQxlSGGOkGRgw59TuVtpF7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;Google Drive - Virus scan warning&lt;/title&gt;&lt;meta http-equiv=\"content-type\" content=\"text/html; charset=utf-8\"/&gt;&lt;style nonce=\"M6ccpFyNkyZIZzZSx29_dw\"&gt;.goog-link-button{position:relative;color:#15c;text-decoration:underline;cursor:pointer}.goog-link-button-disabled{color:#ccc;text-decoration:none;cursor:default}body{color:#222;font:normal 13px/1.4 arial</th>\n",
       "      <th>sans-serif;margin:0}.grecaptcha-badge{visibility:hidden}.uc-main{padding-top:50px;text-align:center}#uc-dl-icon{display:inline-block;margin-top:16px;padding-right:1em;vertical-align:top}#uc-text{display:inline-block;max-width:68ex;text-align:left}.uc-error-caption</th>\n",
       "      <th>.uc-warning-caption{color:#222;font-size:16px}#uc-download-link{text-decoration:none}.uc-name-size a{color:#15c;text-decoration:none}.uc-name-size a:visited{color:#61c;text-decoration:none}.uc-name-size a:active{color:#d14836;text-decoration:none}.uc-footer{color:#777;font-size:11px;padding-bottom:5ex;padding-top:5ex;text-align:center}.uc-footer a{color:#15c}.uc-footer a:visited{color:#61c}.uc-footer a:active{color:#d14836}.uc-footer-divider{color:#ccc;width:100%}.goog-inline-block{position:relative;display:-moz-inline-box;display:inline-block}* html .goog-inline-block{display:inline}*:first-child+html .goog-inline-block{display:inline}sentinel{}&lt;/style&gt;&lt;link rel=\"icon\" href=\"//ssl.gstatic.com/docs/doclist/images/drive_2022q3_32dp.png\"/&gt;&lt;/head&gt;&lt;body&gt;&lt;div class=\"uc-main\"&gt;&lt;div id=\"uc-dl-icon\" class=\"image-container\"&gt;&lt;div class=\"drive-sprite-aux-download-file\"&gt;&lt;/div&gt;&lt;/div&gt;&lt;div id=\"uc-text\"&gt;&lt;p class=\"uc-warning-caption\"&gt;Google Drive can't scan this file for viruses.&lt;/p&gt;&lt;p class=\"uc-warning-subcaption\"&gt;&lt;span class=\"uc-name-size\"&gt;&lt;a href=\"/open?id=1Tit_Fz9pfQhQxlSGGOkGRgw59TuVtpF7\"&gt;train.en&lt;/a&gt; (954M)&lt;/span&gt; is too large for Google to scan for viruses. Would you still like to download this file?&lt;/p&gt;&lt;form id=\"download-form\" action=\"https://drive.usercontent.google.com/download\" method=\"get\"&gt;&lt;input type=\"submit\" id=\"uc-download-link\" class=\"goog-inline-block jfk-button jfk-button-action\" value=\"Download anyway\"/&gt;&lt;input type=\"hidden\" name=\"id\" value=\"1Tit_Fz9pfQhQxlSGGOkGRgw59TuVtpF7\"&gt;&lt;input type=\"hidden\" name=\"export\" value=\"download\"&gt;&lt;input type=\"hidden\" name=\"confirm\" value=\"t\"&gt;&lt;input type=\"hidden\" name=\"uuid\" value=\"8f8d43f2-7ccf-41f7-bfe2-c699ab864b26\"&gt;&lt;/form&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=\"uc-footer\"&gt;&lt;hr class=\"uc-footer-divider\"&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [<!DOCTYPE html><html><head><title>Google Drive - Virus scan warning</title><meta http-equiv=\"content-type\" content=\"text/html; charset=utf-8\"/><style nonce=\"M6ccpFyNkyZIZzZSx29_dw\">.goog-link-button{position:relative;color:#15c;text-decoration:underline;cursor:pointer}.goog-link-button-disabled{color:#ccc;text-decoration:none;cursor:default}body{color:#222;font:normal 13px/1.4 arial, sans-serif;margin:0}.grecaptcha-badge{visibility:hidden}.uc-main{padding-top:50px;text-align:center}#uc-dl-icon{display:inline-block;margin-top:16px;padding-right:1em;vertical-align:top}#uc-text{display:inline-block;max-width:68ex;text-align:left}.uc-error-caption, .uc-warning-caption{color:#222;font-size:16px}#uc-download-link{text-decoration:none}.uc-name-size a{color:#15c;text-decoration:none}.uc-name-size a:visited{color:#61c;text-decoration:none}.uc-name-size a:active{color:#d14836;text-decoration:none}.uc-footer{color:#777;font-size:11px;padding-bottom:5ex;padding-top:5ex;text-align:center}.uc-footer a{color:#15c}.uc-footer a:visited{color:#61c}.uc-footer a:active{color:#d14836}.uc-footer-divider{color:#ccc;width:100%}.goog-inline-block{position:relative;display:-moz-inline-box;display:inline-block}* html .goog-inline-block{display:inline}*:first-child+html .goog-inline-block{display:inline}sentinel{}</style><link rel=\"icon\" href=\"//ssl.gstatic.com/docs/doclist/images/drive_2022q3_32dp.png\"/></head><body><div class=\"uc-main\"><div id=\"uc-dl-icon\" class=\"image-container\"><div class=\"drive-sprite-aux-download-file\"></div></div><div id=\"uc-text\"><p class=\"uc-warning-caption\">Google Drive can't scan this file for viruses.</p><p class=\"uc-warning-subcaption\"><span class=\"uc-name-size\"><a href=\"/open?id=1Tit_Fz9pfQhQxlSGGOkGRgw59TuVtpF7\">train.en</a> (954M)</span> is too large for Google to scan for viruses. Would you still like to download this file?</p><form id=\"download-form\" action=\"https://drive.usercontent.google.com/download\" method=\"get\"><input type=\"submit\" id=\"uc-download-link\" class=\"goog-inline-block jfk-button jfk-button-action\" value=\"Download anyway\"/><input type=\"hidden\" name=\"id\" value=\"1Tit_Fz9pfQhQxlSGGOkGRgw59TuVtpF7\"><input type=\"hidden\" name=\"export\" value=\"download\"><input type=\"hidden\" name=\"confirm\" value=\"t\"><input type=\"hidden\" name=\"uuid\" value=\"8f8d43f2-7ccf-41f7-bfe2-c699ab864b26\"></form></div></div><div class=\"uc-footer\"><hr class=\"uc-footer-divider\"></div></body></html>]\n",
       "Index: []"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1MB [00:00, 1940.91MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "# URL of the file\n",
    "url = \"https://drive.google.com/uc?export=download&id=1Tit_Fz9pfQhQxlSGGOkGRgw59TuVtpF7\"\n",
    "\n",
    "# Start a session\n",
    "session = requests.Session()\n",
    "\n",
    "# Get the initial response to handle redirections and fetch cookies\n",
    "response = session.get(url, stream=True)\n",
    "\n",
    "# Find the confirm token in the response text\n",
    "for key, value in response.cookies.items():\n",
    "    if key.startswith('download_warning'):\n",
    "        confirm_token = value\n",
    "        break\n",
    "else:\n",
    "    confirm_token = None\n",
    "\n",
    "if confirm_token:\n",
    "    params = {'id': '1Tit_Fz9pfQhQxlSGGOkGRgw59TuVtpF7', 'confirm': confirm_token}\n",
    "    response = session.get(url, params=params, stream=True)\n",
    "\n",
    "# Total file size in bytes\n",
    "file_size = int(response.headers.get('Content-Length', 0))\n",
    "\n",
    "# Download the file in chunks and display progress\n",
    "chunk_size = 10240\n",
    "with open(\"data/downloaded_file.en\", \"wb\") as file:\n",
    "    for data in tqdm(response.iter_content(chunk_size=chunk_size), total=file_size // chunk_size, unit='MB'):\n",
    "        file.write(data)\n",
    "\n",
    "print(\"File downloaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "import time \n",
    "from multiprocessing import cpu_count \n",
    "from multiprocessing.pool import ThreadPool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1KB [00:00, 1154.82KB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_confirm_token(response):\n",
    "    for key, value in response.cookies.items():\n",
    "        if key.startswith('download_warning'):\n",
    "            return value\n",
    "    return None\n",
    "\n",
    "def download_file_from_google_drive(file_id, destination):\n",
    "    URL = \"https://drive.google.com/uc?export=download\"\n",
    "    \n",
    "    with requests.Session() as session:\n",
    "        response = session.get(URL, params={'id': file_id}, stream=True)\n",
    "        token = get_confirm_token(response)\n",
    "\n",
    "        if token:\n",
    "            params = {'id': file_id, 'confirm': token}\n",
    "            response = session.get(URL, params=params, stream=True)\n",
    "        \n",
    "        save_response_content(response, destination)\n",
    "\n",
    "def save_response_content(response, destination):\n",
    "    chunk_size = 32 * 1024\n",
    "    total_size = int(response.headers.get('content-length', 0))\n",
    "    with open(destination, \"wb\") as f:\n",
    "        for chunk in tqdm(response.iter_content(chunk_size), total=total_size // chunk_size, unit='KB'):\n",
    "            if chunk:  # filter out keep-alive new chunks\n",
    "                f.write(chunk)\n",
    "\n",
    "file_id = '1Tit_Fz9pfQhQxlSGGOkGRgw59TuVtpF7'\n",
    "destination = 'downloaded_file'\n",
    "\n",
    "download_file_from_google_drive(file_id, destination)\n",
    "\n",
    "print(\"File downloaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taken from this StackOverflow answer: https://stackoverflow.com/a/39225039\n",
    "import requests\n",
    "\n",
    "def download_file_from_google_drive(id, destination):\n",
    "    URL = \"https://drive.google.com/uc?export=download&id=1Tit_Fz9pfQhQxlSGGOkGRgw59TuVtpF7\"\n",
    "\n",
    "    session = requests.Session()\n",
    "\n",
    "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
    "    token = get_confirm_token(response)\n",
    "\n",
    "    if token:\n",
    "        params = { 'id' : id, 'confirm' : token }\n",
    "        response = session.get(URL, params = params, stream = True)\n",
    "\n",
    "    save_response_content(response, destination)    \n",
    "\n",
    "def get_confirm_token(response):\n",
    "    for key, value in response.cookies.items():\n",
    "        if key.startswith('download_warning'):\n",
    "            return value\n",
    "\n",
    "    return None\n",
    "\n",
    "def save_response_content(response, destination):\n",
    "    CHUNK_SIZE = 32768\n",
    "\n",
    "    with open(destination, \"wb\") as f:\n",
    "        for chunk in tqdm(response.iter_content(CHUNK_SIZE)):\n",
    "            if chunk: # filter out keep-alive new chunks\n",
    "                f.write(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 1911.72it/s]\n"
     ]
    }
   ],
   "source": [
    "file_id = '1Tit_Fz9pfQhQxlSGGOkGRgw59TuVtpF'\n",
    "destination = 'data/myfile.en'\n",
    "download_file_from_google_drive(file_id, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"cfilt/iitb-english-hindi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=ds['train'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'translation': [{'en': 'Give your application an accessibility workout',\n",
       "   'hi': 'अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें'},\n",
       "  {'en': 'Accerciser Accessibility Explorer',\n",
       "   'hi': 'एक्सेर्साइसर पहुंचनीयता अन्वेषक'},\n",
       "  {'en': 'The default plugin layout for the bottom panel',\n",
       "   'hi': 'निचले पटल के लिए डिफोल्ट प्लग-इन खाका'},\n",
       "  {'en': 'The default plugin layout for the top panel',\n",
       "   'hi': 'ऊपरी पटल के लिए डिफोल्ट प्लग-इन खाका'},\n",
       "  {'en': 'A list of plugins that are disabled by default',\n",
       "   'hi': 'उन प्लग-इनों की सूची जिन्हें डिफोल्ट रूप से निष्क्रिय किया गया है'},\n",
       "  {'en': 'Highlight duration', 'hi': 'अवधि को हाइलाइट रकें'},\n",
       "  {'en': 'The duration of the highlight box when selecting accessible nodes',\n",
       "   'hi': 'पहुंचनीय आसंधि (नोड) को चुनते समय हाइलाइट बक्से की अवधि'},\n",
       "  {'en': 'Highlight border color',\n",
       "   'hi': 'सीमांत (बोर्डर) के रंग को हाइलाइट करें'},\n",
       "  {'en': 'The color and opacity of the highlight border.',\n",
       "   'hi': 'हाइलाइट किए गए सीमांत का रंग और अपारदर्शिता। '},\n",
       "  {'en': 'Highlight fill color', 'hi': 'भराई के रंग को हाइलाइट करें'}]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=ds['train'][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'translation': [{'en': 'Give your application an accessibility workout',\n",
       "   'hi': 'अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें'},\n",
       "  {'en': 'Accerciser Accessibility Explorer',\n",
       "   'hi': 'एक्सेर्साइसर पहुंचनीयता अन्वेषक'},\n",
       "  {'en': 'The default plugin layout for the bottom panel',\n",
       "   'hi': 'निचले पटल के लिए डिफोल्ट प्लग-इन खाका'},\n",
       "  {'en': 'The default plugin layout for the top panel',\n",
       "   'hi': 'ऊपरी पटल के लिए डिफोल्ट प्लग-इन खाका'},\n",
       "  {'en': 'A list of plugins that are disabled by default',\n",
       "   'hi': 'उन प्लग-इनों की सूची जिन्हें डिफोल्ट रूप से निष्क्रिय किया गया है'},\n",
       "  {'en': 'Highlight duration', 'hi': 'अवधि को हाइलाइट रकें'},\n",
       "  {'en': 'The duration of the highlight box when selecting accessible nodes',\n",
       "   'hi': 'पहुंचनीय आसंधि (नोड) को चुनते समय हाइलाइट बक्से की अवधि'},\n",
       "  {'en': 'Highlight border color',\n",
       "   'hi': 'सीमांत (बोर्डर) के रंग को हाइलाइट करें'},\n",
       "  {'en': 'The color and opacity of the highlight border.',\n",
       "   'hi': 'हाइलाइट किए गए सीमांत का रंग और अपारदर्शिता। '},\n",
       "  {'en': 'Highlight fill color', 'hi': 'भराई के रंग को हाइलाइट करें'},\n",
       "  {'en': 'The color and opacity of the highlight fill.',\n",
       "   'hi': 'हाइलाइट किया गया भराई का रंग और पारदर्शिता। '},\n",
       "  {'en': 'API Browser', 'hi': 'एपीआई विचरक'},\n",
       "  {'en': 'Browse the various methods of the current accessible',\n",
       "   'hi': 'इस समय जिसे प्राप्त किया गया हो, उसकी विभिन्न विधियों (मेथड) में विचरण करें'},\n",
       "  {'en': 'Hide private attributes', 'hi': 'निजी गुणों को छिपाएं'},\n",
       "  {'en': 'Method', 'hi': 'विधि'},\n",
       "  {'en': 'Property', 'hi': 'गुणधर्म'},\n",
       "  {'en': 'Value', 'hi': 'मान'},\n",
       "  {'en': 'IPython Console', 'hi': 'आईपाइथन कन्सोल'},\n",
       "  {'en': 'Interactive console for manipulating currently selected accessible',\n",
       "   'hi': 'इस समय चुने गए एक्सेसेबेल से काम लेने के लिए अंतर्क्रियात्मक कन्सोल'},\n",
       "  {'en': 'Event monitor', 'hi': 'घटना मानिटर'},\n",
       "  {'en': '_ Monitor Events', 'hi': 'घटनाओं को मानिटर करें (_ M) '},\n",
       "  {'en': 'C _ lear Selection', 'hi': 'चुनाव को हटाएं (C _) '},\n",
       "  {'en': 'Everything', 'hi': 'सभी'},\n",
       "  {'en': 'Selected application', 'hi': 'चुने गए अनुप्रयोग'},\n",
       "  {'en': 'Selected accessible', 'hi': 'चुने गए एक्सेसेबेल'},\n",
       "  {'en': 'Source', 'hi': 'स्रोत'},\n",
       "  {'en': 'Event Monitor', 'hi': 'घटना मानिटर'},\n",
       "  {'en': 'Shows events as they occur from selected types and sources',\n",
       "   'hi': 'चुने गए प्रकारों और स्रोतों से घटनाएं जैसे-जैसे घटित होती हैं, उन्हें दर्शाता है'},\n",
       "  {'en': 'Highlight last event entry',\n",
       "   'hi': 'अंतिम प्रविष्ट घटना को हाइलाइट करो'},\n",
       "  {'en': 'Start / stop event recording',\n",
       "   'hi': 'घटना रेकोर्डिंग शुरू करो/रोको'},\n",
       "  {'en': 'Clear event log', 'hi': 'घटना रोजनामचा मिटाओ'},\n",
       "  {'en': '(no description)', 'hi': 'कोई विवरण नहीं'},\n",
       "  {'en': 'Description', 'hi': 'वर्णन'},\n",
       "  {'en': 'Show', 'hi': 'दिखाएं'},\n",
       "  {'en': '_ Accessible', 'hi': 'पहुंचनीय'},\n",
       "  {'en': 'Perform action', 'hi': 'कार्रवाई संपन्न करें'},\n",
       "  {'en': 'Acti _ on', 'hi': 'कार्रवाई (_ o) '},\n",
       "  {'en': 'ID', 'hi': 'आईडी'},\n",
       "  {'en': 'Toolkit', 'hi': 'औजार बक्सा'},\n",
       "  {'en': 'Version', 'hi': 'संस्करण'},\n",
       "  {'en': 'Ap _ plication', 'hi': 'अनुप्रयोग'},\n",
       "  {'en': 'Col _ lection', 'hi': 'संग्रह'},\n",
       "  {'en': '0, 0', 'hi': '0, 0'},\n",
       "  {'en': 'Relative position', 'hi': 'सापेक्ष स्थिति'},\n",
       "  {'en': 'Size', 'hi': 'आकार'},\n",
       "  {'en': 'WIDGET', 'hi': 'विडजेट'},\n",
       "  {'en': 'Layer', 'hi': 'स्तर'},\n",
       "  {'en': 'MDI - Z - order', 'hi': 'एमडीआई-जेड-क्रम'},\n",
       "  {'en': 'Alpha', 'hi': 'अल्फा'},\n",
       "  {'en': 'Absolute position', 'hi': 'निरपेक्ष स्थिति'}]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import get_config\n",
    "config=get_config()\n",
    "ds_raw = load_dataset(config[\"datasource\"])['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizer import bpe_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_src = bpe_tokenizer(config, ds_raw, config['lang_tgt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6781,\n",
       " 594,\n",
       " 4370,\n",
       " 769,\n",
       " 572,\n",
       " 13978,\n",
       " 17,\n",
       " 11890,\n",
       " 534,\n",
       " 4248,\n",
       " 700,\n",
       " 369,\n",
       " 8949,\n",
       " 642,\n",
       " 32,\n",
       " 21983,\n",
       " 531,\n",
       " 764,\n",
       " 11070]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_src.encode(\"चोरी नहीं हत्या करना था मकसद, नफरत से भरे थे हत्‍यारे; हिरासत में चार संदिग्ध\").ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "चोरी नहीं हत्या करना था मकसद , नफरत से भरे थे ह त्‍य ारे ; हिरासत में चार संदिग्ध\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
